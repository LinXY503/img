####æ·±åº¦å½“å‰é—®é¢˜ç°åœ¨å–å‰7å¼ ï¼Œç»“åˆå½“å‰çš„åˆšå¥½9å¼ å¯ä»¥ä¸€æ‰¹æ¬¡è¿›è¡Œå¤„ç†
import rclpy
import time
import sys
import os
import base64
import sqlite3
import ast
import threading
import json
import warnings
import numpy as np
import torch
import clip
from PIL import Image
from datetime import datetime, timedelta
from dateutil import parser
from typing import List, Optional, Dict, Any, Set, Tuple
from concurrent.futures import ThreadPoolExecutor
import queue

# ROS2ç›¸å…³
from rclpy.action import ActionServer
from rclpy.node import Node
from rclpy.client import Client
# ROS2æ ‡å‡†æœåŠ¡æ¥å£
from std_srvs.srv import Trigger
# å¯¼å…¥ç¼–è¯‘åçš„ Action æ¥å£
from api_action.action import ApiAction

# å¯¼å…¥é€šä¹‰åƒé—®
try:
    import dashscope
    from dashscope import MultiModalConversation
    print("dashscope åŒ…å¯¼å…¥æˆåŠŸ", file=sys.stderr)
except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘dashscopeåŒ…ï¼Œè¯·æ‰§è¡Œï¼špip install dashscope --user --break-system-packages", file=sys.stderr)
    sys.exit(1)

# å…³é—­æ— å…³è­¦å‘Šï¼Œå·¥æ§æœºç»ˆç«¯æ•´æ´
warnings.filterwarnings('ignore')

# ====================== åŸºç¡€é…ç½®ï¼ˆç»Ÿä¸€è¡¨åï¼šä»…ä¿ç•™detection_objectsï¼‰=====================
# å¤§æ¨¡å‹é…ç½®
MODEL_NAME = "qwen-vl-max"
TEMPERATURE = 0.0
MAX_TOKENS_CLASSIFY = 64
MAX_TOKENS_INFER = 2048
MAX_TOKENS_FUSION = 3072
MAX_TOKENS_CHAT = 512
MAX_TOKENS_CURRENT_SCENE = 2048  # ç®€å•å½“å‰åœºæ™¯ï¼ˆCLIPï¼‰ä¸“ç”¨
MAX_TOKENS_DEPTH_CURRENT = 3072  # æ·±åº¦å½“å‰åœºæ™¯ï¼ˆ8å¼ å›¾å•æ‰¹æ¬¡ï¼‰ä¸“ç”¨

# æ”¯æŒæ„å›¾ï¼ˆ6ç±»ï¼‰
SUPPORTED_INTENTS = ["è§†è§‰ç†è§£", "ç®€å•ç›®æ ‡æ£€ç´¢", "æ·±åº¦ç›®æ ‡æ£€ç´¢",
                     "ç®€å•å½“å‰åœºæ™¯é—®é¢˜", "æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜", "é—²èŠ"]
# æ·±åº¦æ“ä½œåé¦ˆé—´éš”ï¼ˆç§’ï¼‰
DEPTH_RETRIEVAL_FEEDBACK_INTERVAL = 0.5

# CLIPæ ¸æ˜¾åŠ é€Ÿ+åŒ¹é…é…ç½®ï¼ˆå¯ç›´æ¥ä¿®æ”¹ï¼‰
CONFIDENCE_THRESHOLD = 0.55  # CLIPåŒ¹é…ç½®ä¿¡åº¦é˜ˆå€¼78%
TOP_K = 8                    # å–å‰TOP8åŒ¹é…ç»“æœ
DB_FILE_PATH = "/home/robot-5001/ros2_ws/src/a_vision_memory_qa_node/a_vision_memory_qa_node/detection.db"  # ç»Ÿä¸€DBè·¯å¾„
DB_TABLE_NAME = "detection_objects"  # æ‰€æœ‰é€»è¾‘ç»Ÿä¸€ä½¿ç”¨è¯¥è¡¨
MIN_DETECTION_CONFIDENCE = 0.5 # å…¨å±€æœ€å°æ£€æµ‹ç½®ä¿¡åº¦ï¼Œè¿‡æ»¤ä½ç½®ä¿¡æ•°æ®
TIME_WINDOW_HOURS = 72
# ğŸ”¥ æ ¸å¿ƒå›ºå®šï¼šæ·±åº¦å½“å‰åœºæ™¯ 1å¼ å½“å‰+7å¼ å†å² = 8å¼ ï¼Œå–æ¶ˆåŸMAX_IMG_PER_REQUEST
FIXED_TOTAL_IMG = 8    # æ€»å¼ æ•°
FIXED_CURRENT_IMG = 1  # å›ºå®šå½“å‰å›¾1å¼ 
FIXED_HISTORY_IMG = 7  # å›ºå®šå†å²æœ€æ–°7å¼ 

# COCOæ˜ å°„ï¼šäººå’Œç‰©ç»Ÿä¸€ï¼ˆæ‰€æœ‰åœºæ™¯å…±ç”¨ï¼‰
COCO80_CN2EN = {
    "äºº": "person",
    "è‡ªè¡Œè½¦": "bicycle", "æ±½è½¦": "car", "æ‘©æ‰˜è½¦": "motorcycle", "é£æœº": "airplane", "å…¬äº¤è½¦": "bus",
    "ç«è½¦": "train", "å¡è½¦": "truck", "èˆ¹": "boat", "çº¢ç»¿ç¯": "traffic light", "æ¶ˆé˜²æ “": "fire hydrant",
    "åœè½¦ç‰Œ": "stop sign", "åœè½¦è®¡æ—¶å™¨": "parking meter", "é•¿å‡³": "bench",
    "é¸Ÿ": "bird", "çŒ«": "cat", "ç‹—": "dog", "é©¬": "horse", "ç¾Š": "sheep",
    "ç‰›": "cow", "å¤§è±¡": "elephant", "ç†Š": "bear", "æ–‘é©¬": "zebra", "é•¿é¢ˆé¹¿": "giraffe",
    "èƒŒåŒ…": "backpack", "é›¨ä¼": "umbrella", "åŒ…": "handbag", "é¢†å¸¦": "tie", "è¡Œæç®±": "suitcase",
    "é£ç›˜": "frisbee", "æ»‘é›ªæ¿": "skis", "å†²æµªæ¿": "surfboard", "ç½‘çƒæ‹": "tennis racket", "ç“¶å­": "bottle",
    "é…’æ¯": "wine glass", "æ¯å­": "cup", "å‰å­": "fork", "åˆ€": "knife", "å‹ºå­": "spoon", "ç¢—": "bowl",
    "é¦™è•‰": "banana", "è‹¹æœ": "apple", "ä¸‰æ˜æ²»": "sandwich", "æ©™å­": "orange", "è¥¿å…°èŠ±": "broccoli",
    "èƒ¡èåœ": "carrot", "çƒ­ç‹—": "hot dog", "æŠ«è¨": "pizza", "ç”œç”œåœˆ": "donut", "è›‹ç³•": "cake",
    "æ¤…å­": "chair", "æ²™å‘": "couch", "ç›†æ ½": "potted plant", "åºŠ": "bed", "é¤æ¡Œ": "dining table",
    "é©¬æ¡¶": "toilet", "ç”µè§†": "tv", "ç¬”è®°æœ¬ç”µè„‘": "laptop", "é¼ æ ‡": "mouse", "é¥æ§å™¨": "remote",
    "é”®ç›˜": "keyboard", "æ‰‹æœº": "cell phone", "å¾®æ³¢ç‚‰": "microwave", "çƒ¤ç®±": "oven", "çƒ¤é¢åŒ…æœº": "toaster",
    "æ°´æ§½": "sink", "å†°ç®±": "refrigerator",
    "ä¹¦": "book", "æ—¶é’Ÿ": "clock", "èŠ±ç“¶": "vase", "å‰ªåˆ€": "scissors", "æ³°è¿ªç†Š": "teddy bear",
    "å¹é£æœº": "hair drier", "ç‰™åˆ·": "toothbrush"
}
COCO80_EN2CN = {v: k for k, v in COCO80_CN2EN.items()}
SUPPORTED_TARGETS = list(COCO80_CN2EN.keys())

# ====================== è‹±ç‰¹å°”æ ¸æ˜¾æ»¡è¡€åŠ é€Ÿé…ç½®ï¼ˆCLIPä¸“ç”¨ï¼Œä¿ç•™åŸæœ‰ï¼‰=====================
print("===== è‹±ç‰¹å°” Arrow Lake-P æ ¸æ˜¾åŠ é€Ÿé…ç½® =====")
torch.set_num_threads(8)
torch.backends.mkldnn.enabled = True
torch.backends.mkldnn.benchmark = True
torch.backends.openmp.enabled = True
torch.backends.openmp.omp_num_threads = 8
torch.set_float32_matmul_precision('high')
device = torch.device("cpu")  # MKLDNNè‡ªåŠ¨è°ƒåº¦æ ¸æ˜¾
# åŠ è½½CLIPæ¨¡å‹+æ¨ç†é…ç½®
model, preprocess = clip.load("ViT-B/32", device=device)
model.eval()  # æ¨ç†æ¨¡å¼ï¼Œæé€Ÿ30%
torch.set_grad_enabled(False)  # å…¨å±€å…³é—­æ¢¯åº¦ï¼Œçœæ˜¾å­˜
# æ‰“å°åŠ é€ŸéªŒè¯
print(f"âœ… MKLDNNæ ¸æ˜¾åŠ é€Ÿç”Ÿæ•ˆ: {torch.backends.mkldnn.is_available()}")
print(f"âœ… CLIPæ¨¡å‹: ViT-B/32 | çº¿ç¨‹æ•°:8 | åŒ¹é…é˜ˆå€¼:{CONFIDENCE_THRESHOLD*100}%")
print(f"âœ… å…¨å±€DBè¡¨ï¼š{DB_TABLE_NAME} | ç½®ä¿¡åº¦è¿‡æ»¤ï¼š{MIN_DETECTION_CONFIDENCE*100}%")
print(f"âœ… æ·±åº¦å½“å‰åœºæ™¯å›ºå®šè§„åˆ™ï¼š1å¼ å½“å‰å›¾ + 7å¼ å†å²æœ€æ–°å›¾ = 8å¼ ï¼Œå•æ‰¹æ¬¡ç›´è¿å¤§æ¨¡å‹")
print("="*70 + "\n")

# -------------------------- CLIPå¼‚æ­¥æ¨ç†é…ç½®ï¼ˆæ ¸æ˜¾ä¸“å±ï¼Œä¿®å¤é˜Ÿåˆ—é˜»å¡ï¼‰ --------------------------
QUEUE_SIZE = 2
BATCH_SIZE = 32
img_queue = queue.Queue(maxsize=QUEUE_SIZE)
all_features = []
batch_lock = threading.Lock()

# ğŸ”¥ ä¿®æ”¹ï¼šç»Ÿä¸€ä½¿ç”¨detection_objectsè¡¨ï¼Œå­—æ®µé€‚é…çœŸå®è¡¨ç»“æ„
def filter_matched_image_paths(target_categories: List[str], db_path: str = DB_FILE_PATH) -> List[str]:
    """CLIPä¸“ç”¨ï¼šDBç±»åˆ«ç­›é€‰+æ—¶é—´çª—å£é™åˆ¶ï¼Œå»é‡è¿”å›å›¾åƒè·¯å¾„
    ç»Ÿä¸€ä½¿ç”¨detection_objectsè¡¨ï¼Œæ”¯æŒç©ºåˆ—è¡¨ï¼ˆèƒŒæ™¯å›¾ï¼‰å…¨é‡ç­›é€‰
    """
    target_set: Set[str] = set([cat.strip().lower() for cat in target_categories])
    matched_image_map: dict = {}  # key:image_id å»é‡ï¼Œvalue:original_path
    conn = None
    now = datetime.now()
    window_start = now - timedelta(hours=TIME_WINDOW_HOURS)
    # æ—¥å¿—ï¼šåŒºåˆ†æ­£å¸¸ç­›é€‰/èƒŒæ™¯å›¾å…¨é‡ç­›é€‰
    if target_set:
        print(f"ğŸ“Œ CLIPç±»åˆ«ç­›é€‰ï¼šä»…ç­›é€‰ {TIME_WINDOW_HOURS} å°æ—¶å†…[{target_set}]ç›¸å…³å›¾åƒ", file=sys.stderr)
    else:
        print(f"ğŸ“Œ CLIPèƒŒæ™¯å›¾æ¨¡å¼ï¼šè·³è¿‡ç±»åˆ«ç­›é€‰ï¼Œå– {TIME_WINDOW_HOURS} å°æ—¶å†…æ‰€æœ‰å»é‡å›¾åƒ", file=sys.stderr)

    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        # åŸºç¡€SQLï¼šç»Ÿä¸€ä½¿ç”¨detection_objectsè¡¨ï¼ŒæŸ¥è¯¢å¿…è¦å­—æ®µ
        base_sql = f"SELECT image_id, label_name, original_path, save_time FROM {DB_TABLE_NAME} WHERE 1=1"
        params = []
        # æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¿…åŠ ï¼‰
        base_sql += " AND save_time BETWEEN ? AND ?"
        params.extend([window_start.strftime('%Y-%m-%d %H:%M:%S'), now.strftime('%Y-%m-%d %H:%M:%S')])
        # å…¨å±€ç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆå¿…åŠ ï¼‰
        base_sql += " AND confidence >= ?"
        params.append(MIN_DETECTION_CONFIDENCE)
        # å¤šç›®æ ‡ç­›é€‰ï¼šæœ‰ç±»åˆ«åˆ™åŠ ï¼Œæ— åˆ™è·³è¿‡ï¼ˆèƒŒæ™¯å›¾ï¼‰
        if target_set:
            # ä¸­æ–‡è½¬è‹±æ–‡ï¼ˆé€‚é…DBä¸­labelä¸ºè‹±æ–‡ï¼‰
            en_targets = [COCO80_CN2EN.get(cat, cat) for cat in target_set if cat in COCO80_CN2EN]
            if en_targets:
                placeholders = ', '.join(['?'] * len(en_targets))
                base_sql += f" AND label_name IN ({placeholders})"
                params.extend(en_targets)
        # æ’åº
        base_sql += " ORDER BY image_id ASC"
        cursor.execute(base_sql, params)
        rows = cursor.fetchall()

        if not rows:
            print(f"âš ï¸  æ•°æ®åº“{DB_TABLE_NAME}è¡¨æ— ç¬¦åˆæ¡ä»¶æ•°æ®", file=sys.stderr)
            return []

        for row in rows:
            image_id = row["image_id"]
            original_path = row["original_path"].strip() if row["original_path"] else ""
            # æ ¡éªŒè·¯å¾„å’Œimage_idï¼Œå»é‡
            if not original_path or image_id in matched_image_map:
                continue
            # å»é‡å­˜å‚¨
            matched_image_map[image_id] = original_path

    except sqlite3.Error as e:
        print(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}", file=sys.stderr)
        return []
    finally:
        if conn:
            conn.close()

    matched_paths: List[str] = list(matched_image_map.values())
    # æ—¥å¿—ï¼šæ‰“å°ç­›é€‰ç»“æœ
    if target_set:
        print(f"\nğŸ“Š DBç±»åˆ«ç­›é€‰å®Œæˆï¼šç›®æ ‡ç±»åˆ«={target_categories} | åŒ¹é…{len(matched_paths)}å¼ å”¯ä¸€å›¾åƒ", file=sys.stderr)
    else:
        print(f"\nğŸ“Š DBèƒŒæ™¯å›¾ç­›é€‰å®Œæˆï¼šå…¨é‡å–å›¾ | åŒ¹é…{len(matched_paths)}å¼ å”¯ä¸€å›¾åƒ", file=sys.stderr)
    return matched_paths

# ğŸ”¥ ä¿®æ”¹ï¼šç»Ÿä¸€è¡¨åï¼Œå­—æ®µé€‚é…detection_objects
def get_all_db_rows_by_path(image_path: str, db_path: str = DB_FILE_PATH) -> List[Dict[str, Any]]:
    """CLIPä¸“ç”¨ï¼šæ ¹æ®å›¾åƒè·¯å¾„æŸ¥è¯¢detection_objectsè¡¨æ‰€æœ‰å¯¹åº”è¡Œæ•°æ®"""
    conn = None
    db_rows = []
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        sql = f"SELECT * FROM {DB_TABLE_NAME} WHERE original_path = ? ORDER BY save_time DESC"
        cursor.execute(sql, (image_path,))
        rows = cursor.fetchall()
        db_rows = [dict(row) for row in rows]
    except sqlite3.Error as e:
        print(f"âŒ è·¯å¾„æŸ¥DBå¤±è´¥ï¼š{str(e)} | è·¯å¾„ï¼š{image_path[-50:]}", file=sys.stderr)
    finally:
        if conn:
            conn.close()
    return db_rows

# ====================== æ–°å¢ï¼šJSONåºåˆ—åŒ–å…¼å®¹å‡½æ•°ï¼ˆæ ¸å¿ƒä¿®å¤float32æŠ¥é”™ï¼‰=====================
def convert_to_json_serializable(data: Any) -> Any:
    """é€’å½’è½¬æ¢éJSONå¯åºåˆ—åŒ–ç±»å‹ä¸ºPythonåŸºç¡€ç±»å‹ï¼Œå¤„ç†numpy/bytesç­‰"""
    if isinstance(data, (np.float32, np.float64, np.float16)):
        return float(data)
    elif isinstance(data, (np.int64, np.int32, np.uint32, np.uint64)):
        return int(data)
    elif isinstance(data, bytes):
        return data.decode('utf-8', errors='ignore')
    elif isinstance(data, dict):
        return {k: convert_to_json_serializable(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [convert_to_json_serializable(item) for item in data]
    else:
        return data

# ====================== CLIPå·¥å…·å‡½æ•°ï¼ˆå¼‚æ­¥+æ ¸æ˜¾åŠ é€Ÿ+å¼‚å¸¸å…œåº•ï¼Œä¿®å¤é˜Ÿåˆ—å’Œå›¾ç‰‡å…³é—­ï¼‰=====================
def load_and_preprocess(img_path: str) -> torch.Tensor:
    """CPUåŠ è½½å›¾ç‰‡ï¼Œå¼‚å¸¸è¿”å›å…¨0å¼ é‡ï¼Œä½¿ç”¨withä¸Šä¸‹æ–‡å…³é—­å›¾ç‰‡"""
    try:
        with Image.open(img_path).convert("RGB") as img:
            return preprocess(img)
    except Exception as e:
        print(f"âš ï¸  å›¾ç‰‡å¤„ç†å¤±è´¥: {img_path[-50:]} | {str(e)}", file=sys.stderr)
        return torch.zeros(3, 224, 224)

def infer_batch(batch_imgs: List[torch.Tensor]) -> None:
    """æ ¸æ˜¾æ‰¹é‡æ¨ç†ï¼Œæå–ç‰¹å¾"""
    global all_features
    batch_tensor = torch.stack(batch_imgs)
    with torch.no_grad():
        batch_features = model.encode_image(batch_tensor)
        batch_features = batch_features / batch_features.norm(dim=-1, keepdim=True)
    batch_np = batch_features.detach().cpu().numpy()
    with batch_lock:
        all_features.append(batch_np)

def producer(img_paths: List[str]) -> None:
    """ç”Ÿäº§è€…ï¼š8çº¿ç¨‹åŠ è½½å›¾ç‰‡ï¼Œå–‚ç»™æ ¸æ˜¾ï¼Œä¿®å¤é˜Ÿåˆ—puté˜»å¡"""
    with ThreadPoolExecutor(max_workers=8) as executor:
        for img_tensor in executor.map(load_and_preprocess, img_paths):
            img_queue.put(img_tensor, block=True, timeout=5.0)  # å¢åŠ é˜»å¡å’Œè¶…æ—¶
    img_queue.put(None)  # ç”Ÿäº§å®Œæˆä¿¡å·

def consumer() -> None:
    """æ¶ˆè´¹è€…ï¼šæ ¸æ˜¾å‡‘æ‰¹æ¬¡æ¨ç†ï¼Œæ— ç©ºç­‰"""
    batch_imgs = []
    while True:
        img_tensor = img_queue.get()
        if img_tensor is None:
            if batch_imgs:
                infer_batch(batch_imgs)
            break
        batch_imgs.append(img_tensor)
        if len(batch_imgs) >= BATCH_SIZE:
            infer_batch(batch_imgs)
            batch_imgs = []

def extract_image_features_batch(img_paths: List[str]) -> np.ndarray:
    """å°è£…å¼‚æ­¥ç‰¹å¾æå–ï¼Œè¿”å›numpyç‰¹å¾æ•°ç»„"""
    global all_features
    all_features = []
    prod_thread = threading.Thread(target=producer, args=(img_paths,))
    cons_thread = threading.Thread(target=consumer)
    prod_thread.start()
    cons_thread.start()
    prod_thread.join()
    cons_thread.join()
    return np.concatenate(all_features, axis=0) if all_features else np.array([])

def run_clip_matching(query_img_path: str, candidate_img_paths: List[str]) -> List[Dict[str, Any]]:
    """CLIPæ ¸æ˜¾åŒ¹é…ï¼Œè¿”å›TOP8å†å²åŒ¹é…å¤§åˆ—è¡¨ï¼ˆå«rank/confidence/db_rowsï¼‰ï¼Œå¢åŠ è·¯å¾„æ ¡éªŒ"""
    if not candidate_img_paths:
        print(f"\nâŒ æ— å€™é€‰å›¾åƒï¼Œç»ˆæ­¢CLIPåŒ¹é…", file=sys.stderr)
        return []
    # æ ¡éªŒæŸ¥è¯¢å›¾æ˜¯å¦å­˜åœ¨
    if not os.path.exists(query_img_path):
        print(f"\nâŒ æŸ¥è¯¢å›¾ä¸å­˜åœ¨ï¼š{query_img_path[-50:]}ï¼Œç»ˆæ­¢CLIPåŒ¹é…", file=sys.stderr)
        return []

    print(f"\n" + "="*70, file=sys.stderr)
    print(f"===== ğŸš€ å¼€å§‹CLIPæ ¸æ˜¾åŒ¹é…ï¼ˆå…±{len(candidate_img_paths)}å¼ å€™é€‰å›¾ï¼‰ =====", file=sys.stderr)
    print("="*70 + "\n", file=sys.stderr)
    total_start = time.time()

    try:
        with Image.open(query_img_path).convert("RGB") as query_img:  # withä¸Šä¸‹æ–‡å…³é—­å›¾ç‰‡
            query_img_tensor = preprocess(query_img).unsqueeze(0)
        with torch.no_grad():
            query_feature = model.encode_image(query_img_tensor)
            query_feature = query_feature / query_feature.norm(dim=-1, keepdim=True)
        query_feature = query_feature.detach().cpu().numpy()[0]
        print(f"âœ… æŸ¥è¯¢å›¾ç‰¹å¾æå–å®Œæˆ", file=sys.stderr)
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å›¾ç‰¹å¾æå–å¤±è´¥ï¼š{str(e)}", file=sys.stderr)
        return []

    candidate_features = extract_image_features_batch(candidate_img_paths)
    if candidate_features.size == 0:
        print("âŒ å€™é€‰å›¾ç‰¹å¾æå–å¤±è´¥", file=sys.stderr)
        return []
    print(f"âœ… å€™é€‰å›¾ç‰¹å¾æå–å®Œæˆ | ç»´åº¦ï¼š{candidate_features.shape}", file=sys.stderr)

    similarities = np.dot(candidate_features, query_feature)
    match_pairs = list(zip(candidate_img_paths, similarities))
    match_pairs.sort(key=lambda x: x[1], reverse=True)
    qualified_pairs = [(path, sim) for path, sim in match_pairs if sim >= CONFIDENCE_THRESHOLD and os.path.exists(path)]
    top_qualified_pairs = qualified_pairs[:TOP_K]

    if not top_qualified_pairs:
        print(f"âŒ æ— CLIPç½®ä¿¡åº¦â‰¥{CONFIDENCE_THRESHOLD*100}%çš„æœ‰æ•ˆåŒ¹é…ç»“æœ", file=sys.stderr)
        return []

    history_match_list = []
    for idx, (img_path, confidence) in enumerate(top_qualified_pairs, 1):
        db_all_rows = get_all_db_rows_by_path(img_path)
        history_match_list.append({
            "rank": idx,
            "image_path": img_path,
            "confidence": round(confidence, 4),
            "db_rows": db_all_rows
        })
        short_path = img_path[-30:] if len(img_path) > 30 else img_path
        print(f"TOP{idx:2d} | è·¯å¾„ï¼š{short_path:30s} | ç½®ä¿¡åº¦ï¼š{confidence:.4f} ({confidence*100:.2f}%)", file=sys.stderr)

    total_cost = round((time.time() - total_start) * 1000, 2)
    print(f"\nâœ… CLIPåŒ¹é…å®Œæˆ | æ€»è€—æ—¶ï¼š{total_cost} ms | ç”Ÿæˆ{len(history_match_list)}æ¡å†å²åŒ¹é…æ•°æ®", file=sys.stderr)
    print("="*70, file=sys.stderr)
    return history_match_list

# ====================== æ ¸å¿ƒå°è£…å‡½æ•°ï¼ˆå½“å‰æ•°æ®+å†å²æ•°æ® æ•´åˆï¼šæ–°å¢å®æ—¶XYZåæ ‡ï¼‰=====================
def package_final_data(target_categories: List[str], target_xyz: List[List[float]], history_match_list: List[Dict[str, Any]]) -> Dict[str, Any]:
    """æœ€ç»ˆå°è£…ï¼šå½“å‰åœºæ™¯æ•°æ®ï¼ˆç±»åˆ«+æ—¶é—´+å®æ—¶XYZåæ ‡ï¼‰ + å†å²åŒ¹é…æ•°æ®ï¼Œå…¼å®¹ç©ºç±»åˆ«/ç©ºXYZï¼ˆèƒŒæ™¯å›¾ï¼‰"""
    current_scene_data = {
        "target_categories": target_categories if target_categories else ["æ— æœ‰æ•ˆç›®æ ‡ï¼ˆèƒŒæ™¯å›¾ï¼‰"],
        "target_xyz_coords": target_xyz if target_xyz else [],
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
        "scene_type": "èƒŒæ™¯å›¾" if not target_categories else "æ­£å¸¸åœºæ™¯"  # æ–°å¢ï¼šæ ‡è®°åœºæ™¯ç±»å‹ï¼Œæ–¹ä¾¿å¤§æ¨¡å‹æ¨ç†
    }
    final_package_data = {
        "current_scene": current_scene_data,
        "history_matches": history_match_list
    }
    final_package_data = convert_to_json_serializable(final_package_data)
    return final_package_data

# =============================================================================
# ä¸»æœåŠ¡ç«¯èŠ‚ç‚¹ï¼šæ•´åˆåŸæœ‰æ‰€æœ‰é€»è¾‘ + æ·±åº¦å½“å‰åœºæ™¯ã€8å¼ å›¾å•æ‰¹æ¬¡ã€‘æ ¸å¿ƒé‡æ„
# =============================================================================
class IntentClassifyAnswerServer(Node):
    def __init__(self):
        super().__init__('intent_classify_answer_server')
        # åˆ›å»ºActionæœåŠ¡ç«¯
        self._action_server = ActionServer(
            self,
            ApiAction,
            'intent_classify',
            self.execute_callback
        )
        # æ·±åº¦æ“ä½œçŠ¶æ€æ ‡è¯†ï¼šæ§åˆ¶åé¦ˆçº¿ç¨‹å¯åœ
        self.is_depth_retrieving = False
        self.total_start = 0.0  # å…¨å±€å¼€å§‹æ—¶é—´ï¼ˆä¾›åé¦ˆçº¿ç¨‹ï¼‰

        # å”¯ä¸€ROS2å®¢æˆ·ç«¯ï¼šç®€å•/æ·±åº¦å½“å‰åœºæ™¯ å…±ç”¨ /get_capture_labels_paths æœåŠ¡
        self.common_ros2_client = self.create_client(Trigger, "/get_capture_labels_paths")
        max_retry = 10
        retry_count = 0
        while not self.common_ros2_client.wait_for_service(timeout_sec=1.0) and retry_count < max_retry:
            self.get_logger().warn(f"ç­‰å¾…å…±ç”¨ROS2æœåŠ¡ç«¯ /get_capture_labels_paths ä¸Šçº¿...ï¼ˆ{retry_count+1}/{max_retry}ï¼‰")
            retry_count += 1
        if retry_count >= max_retry:
            self.get_logger().fatal("âŒ è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæœªè¿æ¥åˆ°å…±ç”¨ROS2æœåŠ¡ç«¯ï¼")
            sys.exit(1)
        self.get_logger().info("âœ… å·²è¿æ¥å…±ç”¨ROS2æ•°æ®æœåŠ¡ç«¯ï¼ˆç®€å•/æ·±åº¦å½“å‰åœºæ™¯å…±ç”¨ï¼‰ï¼")

        # åˆå§‹åŒ–é€šä¹‰åƒé—®API+æ ¡éªŒDB/è¡¨
        self._init_dashscope_api()
        self._check_db_and_table()  # ç®€åŒ–è¡¨æ ¡éªŒï¼Œä»…æ ¡éªŒç›®æ ‡è¡¨

        # åˆå§‹åŒ–æ—¥å¿—æç¤ºï¼ˆçªå‡º8å¼ å›¾å›ºå®šè§„åˆ™ï¼‰
        self.get_logger().info("="*60)
        self.get_logger().info("ğŸ“Œ æ„å›¾åˆ†ç±» + å¤šæ¨¡æ€æ¨ç†æœåŠ¡ç«¯ï¼ˆCLIP+8å¼ å›¾å•æ‰¹æ¬¡æ·±åº¦æ¨ç†ç‰ˆ + æ—¶é—´ç­›é€‰ï¼‰")
        self.get_logger().info(f"ğŸ”§ æ”¯æŒæ„å›¾ï¼š{SUPPORTED_INTENTS}")
        self.get_logger().info(f"âš¡ å…±ç”¨æœåŠ¡ï¼š/get_capture_labels_pathsï¼ˆç®€å•/æ·±åº¦å½“å‰åœºæ™¯å…±ç”¨ï¼‰")
        self.get_logger().info(f"ğŸ“‚ DBè·¯å¾„ï¼š{DB_FILE_PATH} | å…¨å±€ç»Ÿä¸€è¡¨ï¼š{DB_TABLE_NAME}")
        self.get_logger().info(f"ğŸ” CLIPé…ç½®ï¼šViT-B/32 | é˜ˆå€¼{CONFIDENCE_THRESHOLD*100}% | TOP{TOP_K} | æ ¸æ˜¾åŠ é€Ÿ")
        self.get_logger().info(f"ğŸ“ æ·±åº¦å½“å‰åœºæ™¯æ ¸å¿ƒè§„åˆ™ï¼š1å¼ å½“å‰å®æ—¶å›¾ + 7å¼ å†å²æœ€æ–°å›¾ = 8å¼ ï¼Œå•æ‰¹æ¬¡ç›´è¿å¤§æ¨¡å‹")
        self.get_logger().info(f"ğŸ” æ·±åº¦æ“ä½œæ”¯æŒï¼š{len(SUPPORTED_TARGETS)}ç±»ç›®æ ‡ï¼ˆå«äºº/ç‰©ï¼‰")
        self.get_logger().info(f"ğŸ–¼ï¸  å…¼å®¹èƒŒæ™¯å›¾ï¼šæ— ç›®æ ‡/ç©ºXYZæ—¶è‡ªåŠ¨é€‚é…ï¼Œæ·±åº¦åœºæ™¯æ­£å¸¸æ¨ç†")
        self.get_logger().info("="*60 + "\n")

    def _init_dashscope_api(self):
        """åˆå§‹åŒ–é€šä¹‰åƒé—®API"""
        self.api_key = os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key or len(self.api_key) < 30:
            self.get_logger().fatal("âŒ ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æœªè®¾ç½®æˆ–æ ¼å¼é”™è¯¯ï¼")
            self.get_logger().fatal("ğŸ‘‰ export DASHSCOPE_API_KEY=ä½ çš„é˜¿é‡Œäº‘API_KEY")
            sys.exit(1)
        dashscope.api_key = self.api_key
        self.get_logger().info("âœ… é€šä¹‰åƒé—®API Key åˆå§‹åŒ–æˆåŠŸ\n")

    def _check_db_and_table(self):
        """æ ¡éªŒDBæ–‡ä»¶+å…¨å±€ç»Ÿä¸€è¡¨detection_objectsæ˜¯å¦å­˜åœ¨"""
        if not os.path.exists(DB_FILE_PATH):
            self.get_logger().fatal(f"âŒ DBæ–‡ä»¶ä¸å­˜åœ¨: {DB_FILE_PATH}")
            sys.exit(1)
        # æ ¡éªŒè¡¨æ˜¯å¦å­˜åœ¨
        conn = None
        try:
            conn = sqlite3.connect(DB_FILE_PATH)
            cursor = conn.cursor()
            cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{DB_TABLE_NAME}';")
            if not cursor.fetchone():
                self.get_logger().fatal(f"âŒ å…¨å±€ç»Ÿä¸€è¡¨ {DB_TABLE_NAME} ä¸å­˜åœ¨äºDBä¸­ï¼")
                sys.exit(1)
            self.get_logger().info("âœ… DBæ–‡ä»¶åŠå…¨å±€ç»Ÿä¸€è¡¨æ ¡éªŒé€šè¿‡ï¼")
        except sqlite3.Error as e:
            self.get_logger().fatal(f"âŒ æ ¡éªŒDB/è¡¨å¤±è´¥: {str(e)}")
            sys.exit(1)
        finally:
            if conn:
                conn.close()

    # ---------------------- å…±ç”¨ï¼šè°ƒç”¨ROS2æœåŠ¡è·å–å½“å‰æ•°æ®ï¼ˆå…¼å®¹ç©ºç±»åˆ«/ç©ºXYZï¼‰----------------------
    def get_common_current_data(self) -> Optional[Dict[str, Any]]:
        """
        ç®€å•/æ·±åº¦å½“å‰åœºæ™¯å…±ç”¨ï¼šè°ƒç”¨/get_capture_labels_pathsè·å–å½“å‰å®æ—¶æ•°æ®
        æ ¸å¿ƒï¼šç©ºç±»åˆ«/ç©ºXYZä¸å†è¿”å›Noneï¼Œè§†ä¸ºæ­£å¸¸èƒŒæ™¯å›¾æ•°æ®
        """
        req = Trigger.Request()
        future = self.common_ros2_client.call_async(req)
        rclpy.spin_until_future_complete(self, future, timeout_sec=5.0)

        if future.result() is None:
            self.get_logger().error("âŒ è°ƒç”¨å…±ç”¨ROS2æœåŠ¡è¶…æ—¶ï¼ˆ5ç§’ï¼‰ï¼Œæ— æ³•è·å–å½“å‰æ•°æ®")
            return None
        response = future.result()
        if not response.success:
            self.get_logger().error(f"âŒ å…±ç”¨ROS2æœåŠ¡æ‰§è¡Œå¤±è´¥ï¼š{response.message}")
            return None

        # è§£ææœåŠ¡ç«¯è¿”å›çš„JSON
        try:
            result_data = json.loads(response.message)
            target_categories = result_data.get("labels", [])
            target_xyz_coords = result_data.get("xyz_coords", [])
            image_paths = result_data.get("image_paths", [])
            
            # æ ¼å¼å…œåº•ä¸ç±»å‹æ ¡éªŒ
            target_categories = target_categories if isinstance(target_categories, list) else []
            target_xyz_coords = target_xyz_coords if isinstance(target_xyz_coords, list) else []
            image_paths = [p.strip() for p in image_paths if isinstance(image_paths, list) and p.strip()]
            query_img_path = image_paths[0] if image_paths else ""

            # ä»…å½“æœ‰ç±»åˆ«ä½†åæ ‡ä¸åŒ¹é…æ—¶æ‰è­¦å‘Šï¼Œä¸ç»ˆæ­¢
            if target_categories and len(target_categories) != len(target_xyz_coords):
                self.get_logger().warning(f"âš ï¸  å…±ç”¨æœåŠ¡è¿”å›æ•°æ®å¼‚å¸¸ï¼šç±»åˆ«æ•°({len(target_categories)})ä¸åæ ‡æ•°({len(target_xyz_coords)})ä¸åŒ¹é…ï¼ŒæŒ‰å®é™…æ•°æ®å¤„ç†")

            # è§£æåæ ‡ä¸ºæ‰å¹³åˆ—è¡¨[x,y,z]
            parsed_xyz = []
            for xyz in target_xyz_coords:
                if isinstance(xyz, list) and len(xyz) >=1 and isinstance(xyz[0], list) and len(xyz[0])==3:
                    parsed_xyz.append(xyz[0])
                elif xyz:  # éç©ºä½†æ ¼å¼é”™è¯¯æ‰è­¦å‘Š
                    self.get_logger().warning(f"âš ï¸  å…±ç”¨æœåŠ¡åæ ‡æ ¼å¼é”™è¯¯ï¼š{xyz}ï¼Œè·³è¿‡è¯¥åæ ‡")

            # ä»…å½“æ— å›¾åƒè·¯å¾„æ—¶è¿”å›Noneï¼Œç©ºç±»åˆ«/ç©ºåæ ‡è§†ä¸ºæ­£å¸¸
            if not query_img_path or not os.path.exists(query_img_path):
                self.get_logger().error(f"âŒ å…±ç”¨æœåŠ¡è¿”å›æ— æ•ˆæŸ¥è¯¢å›¾è·¯å¾„ï¼š{query_img_path}")
                return None

            # æ—¥å¿—åŒºåˆ†æ­£å¸¸åœºæ™¯/èƒŒæ™¯å›¾
            if target_categories and parsed_xyz:
                self.get_logger().info(f"âœ… ä»å…±ç”¨æœåŠ¡è·å–å½“å‰æ•°æ®ï¼šç±»åˆ«={target_categories}ï¼Œåæ ‡={parsed_xyz}ï¼Œå›¾åƒ={query_img_path[-50:]}")
            else:
                self.get_logger().info(f"âœ… ä»å…±ç”¨æœåŠ¡è·å–å½“å‰æ•°æ®ï¼šèƒŒæ™¯å›¾ï¼ˆæ— ç›®æ ‡/ç©ºåæ ‡ï¼‰ï¼Œå›¾åƒ={query_img_path[-50:]}")

            return {
                "query_img_path": query_img_path,
                "target_categories": target_categories,
                "target_xyz": parsed_xyz
            }
        except Exception as e:
            self.get_logger().error(f"âŒ è§£æå…±ç”¨æœåŠ¡æ•°æ®å¤±è´¥ï¼š{str(e)}")
            return None

    # ---------------------- ç®€å•å½“å‰åœºæ™¯æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼ˆä¿ç•™åŸæœ‰ï¼‰----------------------
    def _handle_simple_current_scene(self, user_question: str) -> str:
        """å¤„ç†ç®€å•å½“å‰åœºæ™¯é—®é¢˜ï¼šCLIPç»“æ„åŒ–æ•°æ® + å¤§æ¨¡å‹èåˆæ¨ç†"""
        self.get_logger().info("ğŸ” å¼€å§‹å¤„ç†ç®€å•å½“å‰åœºæ™¯é—®é¢˜ï¼Œæ‰§è¡Œã€ŒCLIPæ•°æ®è·å–+å¤§æ¨¡å‹èåˆæ¨ç†ã€æµç¨‹...")
        clip_structured_data = self._get_clip_structured_data()
        if not clip_structured_data:
            return "âŒ æ— æ³•å›ç­”ä½ çš„é—®é¢˜ï¼šæœªè·å–åˆ°æœ‰æ•ˆçš„åœºæ™¯å›¾åƒï¼ˆæœåŠ¡è°ƒç”¨å¤±è´¥/æ— å›¾åƒè·¯å¾„ï¼‰"
        llm_final_answer = self._llm_infer_with_clip_data(user_question, clip_structured_data)
        return llm_final_answer

    # ---------------------- è·å–CLIPç»“æ„åŒ–æ•°æ®ï¼ˆå…¼å®¹èƒŒæ™¯å›¾ï¼Œä¿ç•™åŸæœ‰ï¼‰----------------------
    def _get_clip_structured_data(self) -> Optional[Dict[str, Any]]:
        """ä»…è·å–CLIPæ ¸æ˜¾åŒ¹é…åçš„ç»“æ„åŒ–æ•°æ®ï¼ˆå­—å…¸ï¼Œå«å®æ—¶XYZï¼‰ï¼Œå…¼å®¹èƒŒæ™¯å›¾"""
        service_data = self.get_common_current_data()
        if not service_data:
            self.get_logger().error("âŒ è·å–CLIPæ•°æ®å¤±è´¥ï¼šæ— æ³•è°ƒç”¨ROS2æœåŠ¡è·å–å®æ—¶åœºæ™¯å›¾åƒ")
            return None
        
        query_img_path = service_data["query_img_path"]
        target_categories = service_data["target_categories"]
        target_xyz = service_data["target_xyz"]
        
        candidate_img_paths = filter_matched_image_paths(target_categories)
        history_match_list = run_clip_matching(query_img_path, candidate_img_paths)
        final_structured_data = package_final_data(target_categories, target_xyz, history_match_list)
        self.get_logger().info("âœ… æˆåŠŸè·å–CLIPç»“æ„åŒ–æ•°æ®ï¼ˆå…¼å®¹èƒŒæ™¯å›¾ï¼‰ï¼Œå³å°†äº¤ç»™å¤§æ¨¡å‹èåˆæ¨ç†")
        return final_structured_data

    # ---------------------- å¤§æ¨¡å‹èåˆæ¨ç†ï¼ˆPrompté€‚é…èƒŒæ™¯å›¾ï¼Œä¿ç•™åŸæœ‰ï¼‰----------------------
    def _llm_infer_with_clip_data(self, user_question: str, clip_data: Dict[str, Any]) -> str:
        """ç®€å•å½“å‰åœºæ™¯ï¼šå¤§æ¨¡å‹èåˆCLIPæ•°æ®+XYZåæ ‡æ¨ç†"""
        self.get_logger().info(f"ğŸ’¬ è°ƒç”¨å¤§æ¨¡å‹èåˆCLIPæ•°æ®æ¨ç†ï¼šé—®é¢˜={user_question[:50]}...")
        infer_start = time.time()
        clip_data_json = json.dumps(clip_data, ensure_ascii=False, indent=2)

        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„æ™ºèƒ½åœºæ™¯åˆ†æåŠ©æ‰‹ï¼Œè´Ÿè´£ç»“åˆ**å½“å‰æ•°æ®å’Œè¿‡å»æ•°æ®è¿›è¡Œé€»è¾‘æ¨ç†â€œ
è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™è¿›è¡Œåˆ†æå’Œå›ç­”ï¼š
1. æ¨ç†ä¾æ®ï¼šä»…åŸºäºä¸‹æ–¹æä¾›çš„ã€CLIPç»“æ„åŒ–æ•°æ®ã€‘ï¼Œä¸è‡†é€ ä»»ä½•ä¿¡æ¯ï¼Œæ•°æ®ä¸è¶³æ—¶æ˜ç¡®è¯´æ˜ï¼›
2. å…³é”®æ•°æ®æ ‡è®°è§£è¯»ï¼š
   - scene_type: èƒŒæ™¯å›¾ â†’ å½“å‰ç”»é¢æ— ä»»ä½•æœ‰æ•ˆç›®æ ‡ï¼Œåªæœ‰èƒŒæ™¯ï¼›æ­£å¸¸åœºæ™¯ â†’ å½“å‰ç”»é¢æ£€æµ‹åˆ°ç›®æ ‡ï¼›
   - target_categories: ["æ— æœ‰æ•ˆç›®æ ‡ï¼ˆèƒŒæ™¯å›¾ï¼‰"] â†’ ç¡®è®¤å½“å‰æ˜¯èƒŒæ™¯å›¾ï¼Œæ— ç›®æ ‡ï¼›
   - current_scene.target_xyz_coords: ç©ºåˆ—è¡¨ â†’ æ— ç›®æ ‡çš„3Dåæ ‡ï¼›
   - history_matches: CLIPæ ¸æ˜¾åŒ¹é…çš„TOP8å†å²ç›¸ä¼¼å›¾åƒï¼ˆrank=åŒ¹é…æ’åï¼Œconfidence=åŒ¹é…ç½®ä¿¡åº¦ï¼Œä»£è¡¨å†å²æ˜¯å¦è§è¿‡è¯¥ç›®æ ‡ï¼‰ï¼›
   - èƒŒæ™¯å›¾å°±æ˜¯å½“å‰å¸§æœ¬æ¥åªæ£€æµ‹åˆ°ç›®æ ‡ç‰©ä½“ï¼Œä½†æ˜¯è¯¥ç‰©ä½“è¢«æ‹¿èµ°äº†ï¼Œè¯¥å›¾ä¸­å°±æ²¡æœ‰åˆ«çš„è¢«æ£€æµ‹åˆ°çš„ç‰©ä½“äº†
3. ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
        1. ä»¥ç”¨æˆ·ä¸ºçš„é—®é¢˜ä¸ºæ ¸å¿ƒï¼Œåªä¾æ®ç»™å®šçš„CLIPæ•°æ®è¿›è¡Œæ¨ç†ï¼Œ**ä¸¥ç¦ç¼–é€ ã€è„‘è¡¥ä»»ä½•æ•°æ®**ã€‚
        2. è‹¥æ•°æ®ä¸­æ²¡æœ‰ç”¨æˆ·è¯¢é—®çš„ç›®æ ‡ä¿¡æ¯ï¼Œç›´æ¥è¯´æ˜â€œæœªæ£€æµ‹åˆ°{{ç›®æ ‡ç‰©å“}}ç›¸å…³ä¿¡æ¯ï¼Œæ— æ³•åˆ¤æ–­â€ã€‚
        3. è‹¥å½“å‰åœºæ™¯ä¸ºèƒŒæ™¯å›¾ã€æ— æœ‰æ•ˆç›®æ ‡ï¼š
        - æœ‰å†å²åŒ¹é… â†’ è¯´æ˜ç›®æ ‡ä¸åœ¨å½“å‰è§†é‡ï¼Œå¯å¼•ç”¨å†å²åŒ¹é…ä¿¡æ¯ï¼›
        - æ— å†å²åŒ¹é… â†’ è¯´æ˜ä»æœªè§è¿‡è¯¥ç›®æ ‡ï¼Œå½“å‰ä¹Ÿæ— ç›®æ ‡ã€‚
        4. è‹¥ä¸ºæ­£å¸¸åœºæ™¯ä¸”æ£€æµ‹åˆ°ç›®æ ‡ï¼Œç»“åˆå®æ—¶XYZåæ ‡ä¸å†å²åŒ¹é…è¯´æ˜ä½ç½®ã€æ˜¯å¦ç§»åŠ¨ç­‰ã€‚
        5. å›ç­”å£è¯­åŒ–ã€ç®€æ´ï¼Œé€‚åˆæœºå™¨äººæ’­æŠ¥ï¼Œä¸è¾“å‡ºä»£ç ã€JSONã€å¤šä½™ç¬¦å·ä¸æ— å…³è§£é‡Šã€‚
        6. è‹¥é—®é¢˜ä¸­æœ‰æ˜æ˜¾å…³è”ä¸”åœ¨CLIPç»“æ„åŒ–æ•°æ®ä¸­å­˜åœ¨ç±»åˆ«çš„ç›®æ ‡ï¼Œåˆ™ä¸€å¹¶è¿›è¡Œè®°å½•åˆ†æ  
        ç¤ºä¾‹ï¼šæˆ‘æ”¾åœ¨è¿™çš„ç“¶å­å‘¢ï¼Ÿæ˜¯è¢«è°æ‹¿èµ°äº†å—ï¼Œè‹¥æœ‰äººæ‹¿èµ°è¯·æç»˜æ‹¿èµ°ç“¶å­çš„äºº -> ç“¶å­ä¸åœ¨å½“å‰è§†é‡é‡Œäº†ï¼Œä¹‹å‰æ˜¯åœ¨ç”»é¢ä¸­å¤®åå·¦çš„ä½ç½®ã€‚æœ‰ä¸€ä¸ªäººåœ¨ç“¶å­é™„è¿‘å‡ºç°ï¼Œè¿™ä¸ªäººç«™åœ¨ç“¶å­å³ä¾§çº¦80å˜ç±³å¤„ï¼Œç©¿ç€æ™®é€šè¡£ç‰©ï¼Œå…·ä½“ç‰¹å¾æ— æ³•è¯†åˆ«
             æˆ‘æ”¾åœ¨è¿™çš„ç“¶å­å‘¢ï¼Ÿæœ‰äººæ‹¿èµ°äº†å—ï¼Ÿ ->  ç“¶å­ä¸åœ¨å½“å‰è§†é‡é‡Œäº†ï¼Œä½†ä¹‹å‰è§è¿‡ï¼Œå½“æ—¶é™„è¿‘æœ‰äººï¼Œå¯èƒ½æ˜¯è¢«é‚£ä¸ªäººæ‹¿èµ°äº† ã€‚æ­¤ç±»é—®é¢˜ä¸å¾—æé€ æ•°æ®ã€‚
ã€ç”¨æˆ·çš„å½“å‰åœºæ™¯é—®é¢˜ã€‘ï¼š{user_question}

ã€CLIPç»“æ„åŒ–æ•°æ®ï¼ˆå«å®æ—¶XYZ/èƒŒæ™¯å›¾æ ‡è®°ï¼‰ã€‘ï¼š
{clip_data_json}"""

        response = MultiModalConversation.call(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": [{"text": prompt}]}],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS_CURRENT_SCENE
        )

        infer_cost = round(time.time() - infer_start, 3)
        if response.status_code != 200:
            err_msg = f"å¤§æ¨¡å‹æ¨ç†å¤±è´¥: {response.message[:60]}"
            self.get_logger().error(f"âŒ {err_msg}ï¼Œè€—æ—¶{infer_cost}s")
            return f"å¤„ç†å¤±è´¥ï¼š{err_msg}"
        
        llm_answer = response.output.choices[0].message.content[0]["text"].strip()
        if not llm_answer:
            llm_answer = "æš‚æ— ç›¸å…³åœºæ™¯æ•°æ®ï¼Œæ— æ³•å›ç­”ä½ çš„é—®é¢˜"
        
        self.get_logger().info(f"âœ… å¤§æ¨¡å‹èåˆCLIPæ•°æ®æ¨ç†å®Œæˆï¼Œè€—æ—¶{infer_cost}s | å›ç­”ï¼š{llm_answer[:100]}...")
        return llm_answer

    # ---------------------- 1ï¼‰æ„å›¾åˆ†ç±»ï¼ˆå‡çº§ç‰ˆï¼šæ”¯æŒæ—¶é—´è§£æï¼‰----------------------
    def _llm_text_classify(self, question):
        # è·å–å½“å‰ç²¾ç¡®æ—¶é—´ï¼Œä¾›å¤§æ¨¡å‹è¿›è¡Œç›¸å¯¹æ—¶é—´è®¡ç®—
        current_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        prompt =f"""ä½ æ˜¯ç²¾å‡†çš„æ„å›¾ä¸æ—¶é—´è§£æå™¨ã€‚å½“å‰ç³»ç»Ÿæ—¶é—´æ˜¯ï¼šã€{current_time_str}ã€‘ã€‚
è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¦æ±‚åˆ†æç”¨æˆ·é—®é¢˜ï¼š
1. è¾“å‡ºæ ¼å¼ï¼šä¸¥æ ¼ä¸”ä»…è¾“å‡º "æ„å›¾|ç›®æ ‡|å¼€å§‹æ—¶é—´|ç»“æŸæ—¶é—´" çš„å­—ç¬¦ä¸²æ ¼å¼ã€‚
   - è‹¥ç”¨æˆ·æœªæŒ‡å®šæ—¶é—´ï¼Œæ—¶é—´å­—æ®µç•™ç©ºã€‚
   - è‹¥ç”¨æˆ·æŒ‡å®šæ—¶é—´ï¼ˆå¦‚â€œæ˜¨å¤©ä¸‹åˆ3ç‚¹åˆ°4ç‚¹â€ï¼‰ï¼Œè¯·åŸºäºå½“å‰ç³»ç»Ÿæ—¶é—´è®¡ç®—å‡ºå‡†ç¡®çš„ "YYYY-MM-DD HH:MM:SS" æ ¼å¼ã€‚
   - åˆ†éš”ç¬¦å¿…é¡»ä½¿ç”¨ | 
    2. æ”¯æŒæ„å›¾ï¼š{SUPPORTED_INTENTS}
    3. æ·±åº¦æ“ä½œæ”¯æŒç›®æ ‡ï¼š{SUPPORTED_TARGETS}
    4. æ ¸å¿ƒåˆ†ç±»è§„åˆ™ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼Œä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
    - è§†è§‰ç†è§£ï¼šè¯¢é—®**å½“å‰/ç°åœ¨/çœ¼å‰/è¿™é‡Œ**çœ‹åˆ°äº†ä»€ä¹ˆã€ç”»é¢å†…å®¹ã€å½“å‰åœºæ™¯æè¿°ï¼Œå±äºå®æ—¶ç”»é¢ç†è§£ã€‚
        ç¤ºä¾‹ï¼šæè¿°ä¸€ä¸‹ç°åœ¨çœ‹åˆ°çš„ç”»é¢ã€‚â†’ è§†è§‰ç†è§£
        ç¤ºä¾‹ï¼šæˆ‘ç°åœ¨åœ¨å“ªï¼Ÿâ†’ è§†è§‰ç†è§£
        ç¤ºä¾‹ï¼šè¿™é‡Œæœ‰ä»€ä¹ˆï¼Ÿâ†’ è§†è§‰ç†è§£
    - ç®€å•ç›®æ ‡æ£€ç´¢ï¼šè¯¢é—®**æœ€è¿‘/åˆšæ‰/ä¹‹å‰**æ˜¯å¦çœ‹åˆ°æŸç›®æ ‡ï¼Œæˆ–å†å²è®°å¿†æ±‡æ€»ï¼Œå±äºå†å²è®°å¿†æŸ¥è¯¢ã€‚
        **æ ¼å¼ï¼šç®€å•ç›®æ ‡æ£€ç´¢|ç›®æ ‡å**ï¼ˆæ— å…·ä½“ç›®æ ‡åˆ™ä¸åŠ |ï¼‰
        ç¤ºä¾‹ï¼šçœ‹è§æ¯å­äº†å—ï¼Ÿâ†’ ç®€å•ç›®æ ‡æ£€ç´¢|æ¯å­
        ç¤ºä¾‹ï¼šæœ‰æ²¡æœ‰äººï¼Ÿâ†’ ç®€å•ç›®æ ‡æ£€ç´¢|äºº
    - æ·±åº¦ç›®æ ‡æ£€ç´¢ï¼šå¯»æ‰¾ç›®æ ‡+å¸¦**å…·ä½“é™æ€ç‰¹å¾**ï¼ˆé¢œè‰²/å½¢çŠ¶/å“ç‰Œï¼‰ã€‚
        ç¤ºä¾‹ï¼šæœ‰æ²¡æœ‰çœ‹è§çº¢è‰²çš„æ¯å­ï¼Ÿâ†’ æ·±åº¦ç›®æ ‡æ£€ç´¢|æ¯å­
        ç¤ºä¾‹ï¼šæœ‰æ²¡æœ‰çœ‹è§ç™¾äº‹å¯ä¹ï¼Ÿ-> æ·±åº¦ç›®æ ‡æ£€ç´¢|ç“¶å­
    - ç®€å•å½“å‰åœºæ™¯é—®é¢˜ï¼šè¯¢é—®ç›®æ ‡å»å‘/å˜åŒ–ï¼ˆæ— ç‰¹å¾ï¼‰ã€‚
        ç¤ºä¾‹ï¼šæ¯å­å»å“ªäº†ï¼Ÿâ†’ ç®€å•å½“å‰åœºæ™¯é—®é¢˜|æ¯å­
        ç¤ºä¾‹ï¼šè¿™ä¸ªæ¯å­æœ‰æ²¡æœ‰å‘ç”Ÿç§»åŠ¨? ->ç®€å•å½“å‰åœºæ™¯é—®é¢˜|æ¯å­
    - æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜ï¼šå¸¦ç‰¹å¾çš„ç›®æ ‡å»å‘/å˜åŒ–ã€‚
        ç¤ºä¾‹ï¼šçº¢è‰²çš„æ¯å­å»å“ªäº†ï¼Ÿâ†’ æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜|æ¯å­
        ç¤ºä¾‹ï¼šç™¾äº‹å¯ä¹å»å“ªäº†ï¼Ÿ->æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜|ç“¶å­
    - é—²èŠï¼šæ— å…³æŸ¥è¯¢ã€‚â†’ é—²èŠ
    5. ç›®æ ‡åæå–è§„åˆ™ï¼šä»…æå–æ ¸å¿ƒåè¯ï¼Œç¦æ­¢ä¿®é¥°è¯ã€‚
   
ç”¨æˆ·é—®é¢˜ï¼š{question}"""

        response = MultiModalConversation.call(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": [{"text": prompt}]}],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS_CLASSIFY
        )

        if response.status_code != 200:
            raise Exception(f"åˆ†ç±»æ¥å£å¤±è´¥: {response.message[:60]}")

        res_text = response.output.choices[0].message.content[0]["text"].strip()
        # æ¸…æ´—ç¬¦å·
        for char in ["ã€", "ã€‘", "(", ")", "[", "]", "{", "}"]:
            res_text = res_text.replace(char, "")
        res_text = res_text.strip()

        # é»˜è®¤å€¼
        intent_type = "é—²èŠ"
        target_cn = None
        start_time = None
        end_time = None

        # è§£æ "æ„å›¾|ç›®æ ‡|å¼€å§‹æ—¶é—´|ç»“æŸæ—¶é—´"
        parts = res_text.split("|")
        if len(parts) >= 1: intent_type = parts[0].strip()
        if len(parts) >= 2: target_cn = parts[1].strip() if parts[1].strip() else None
        if len(parts) >= 3: start_time = parts[2].strip() if parts[2].strip() else None
        if len(parts) >= 4: end_time = parts[3].strip() if parts[3].strip() else None

        # ç›®æ ‡åˆæ³•æ€§æ ¡éªŒ
        if target_cn and target_cn not in SUPPORTED_TARGETS:
            self.get_logger().warning(f"âš ï¸  ç›®æ ‡[{target_cn}]ä¸åœ¨æ”¯æŒåˆ—è¡¨")
            return "é—²èŠ", None, None, None

        if intent_type in SUPPORTED_INTENTS:
            return intent_type, target_cn, start_time, end_time
        else:
            return "é—²èŠ", None, None, None

    # ---------------------- 2ï¼‰æ·±åº¦æ“ä½œä¸“å±ï¼šæŒç»­åé¦ˆçº¿ç¨‹ï¼ˆä¿ç•™åŸæœ‰ï¼‰----------------------
    def _depth_retrieval_feedback_thread(self, goal_handle, feedback):
        """æ·±åº¦æ£€ç´¢/æ·±åº¦å½“å‰åœºæ™¯ æŒç»­å‘å®¢æˆ·ç«¯å‘é€feedback"""
        self.get_logger().info("ğŸ” å¯åŠ¨æ·±åº¦æ“ä½œæŒç»­åé¦ˆçº¿ç¨‹")
        while self.is_depth_retrieving and rclpy.ok() and goal_handle.is_active:
            try:
                feedback.feedback_msg = "æ­£åœ¨æ·±åº¦å¤„ç†ä¸­...ï¼ˆ1å¼ å½“å‰+7å¼ å†å²å›¾ï¼Œå•æ‰¹æ¬¡å¤šæ¨¡æ€æ¨ç†ï¼‰"
                feedback.elapsed_time = round(time.time() - self.total_start, 3)
                goal_handle.publish_feedback(feedback)
            except Exception as e:
                self.get_logger().warning(f"âš ï¸  åé¦ˆçº¿ç¨‹å‘å¸ƒæ¶ˆæ¯å¤±è´¥ï¼š{str(e)[:50]}")
            time.sleep(DEPTH_RETRIEVAL_FEEDBACK_INTERVAL)
        self.get_logger().info("ğŸ” æ·±åº¦æ“ä½œæŒç»­åé¦ˆçº¿ç¨‹åœæ­¢")

    # ---------------------- 3ï¼‰é—²èŠä¸“ç”¨ - çº¯æ–‡æœ¬å¯¹è¯ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰----------------------
    def _llm_chat(self, question):
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„æ™ºèƒ½æœºå™¨äººåŠ©æ‰‹ï¼Œè´Ÿè´£æ—¥å¸¸é—²èŠå¯¹è¯ï¼Œå›ç­”ç®€æ´ã€è‡ªç„¶ã€æ˜“æ‡‚ï¼Œé€‚é…å£è¯­åŒ–äº¤æµï¼Œç®€æ´ä¸ºé¦–è¦ç›®æ ‡ã€‚
ç”¨æˆ·çš„é—²èŠé—®é¢˜ï¼š{question}
è¦æ±‚ï¼šç›´æ¥å›ç­”é—®é¢˜ï¼Œæ— éœ€å¤šä½™å‰ç¼€ï¼Œå›ç­”é•¿åº¦é€‚ä¸­"""
        
        self.get_logger().info(f"ğŸ’¬ è°ƒç”¨å¤§æ¨¡å‹å¤„ç†é—²èŠé—®é¢˜: {question[:50]}...")
        chat_start = time.time()
        response = MultiModalConversation.call(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": [{"text": prompt}]}],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS_CHAT
        )
        chat_cost = round(time.time() - chat_start, 3)

        if response.status_code != 200:
            raise Exception(f"é—²èŠæ¥å£è°ƒç”¨å¤±è´¥: {response.message[:60]}")
        
        chat_ans = response.output.choices[0].message.content[0]["text"].strip()
        if not chat_ans:
            chat_ans = "æˆ‘ä¸å¤ªæ˜ç™½ä½ çš„æ„æ€å‘¢ï¼Œæ¢ä¸ªé—®é¢˜é—®é—®å§ï½"
        
        self.get_logger().info(f"âœ… é—²èŠå›ç­”ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶{chat_cost}s")
        return chat_ans
    
    # ---------------------- ç®€å•ç›®æ ‡æ£€ç´¢æŸ¥è¯¢å‡½æ•°ï¼ˆæ”¯æŒæ—¶é—´è¿‡æ»¤ï¼‰----------------------
    def _filter_clip_target_data(self, target_cn, start_time=None, end_time=None):
        """ç®€å•ç›®æ ‡æ£€ç´¢ä¸“å±ï¼šæŸ¥è¯¢DBï¼Œæ”¯æŒè‡ªå®šä¹‰æ—¶é—´æ®µï¼Œé»˜è®¤72å°æ—¶"""
        now = datetime.now()
        
        # ç¡®å®šæ—¶é—´çª—å£
        if start_time and end_time:
            search_start = start_time
            search_end = end_time
            self.get_logger().info(f"ğŸ•’ å¯ç”¨ç²¾ç¡®æ—¶é—´ç­›é€‰ï¼š{search_start} è‡³ {search_end}")
        else:
            search_start = (now - timedelta(hours=TIME_WINDOW_HOURS)).strftime('%Y-%m-%d %H:%M:%S')
            search_end = now.strftime('%Y-%m-%d %H:%M:%S')

        target_en = COCO80_CN2EN.get(target_cn, target_cn)
        matched_data = []
        conn = None

        try:
            conn = sqlite3.connect(DB_FILE_PATH)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            sql = f"""SELECT save_time, label_name, confidence, cam_x, cam_y, cam_z, original_path, image_id
                    FROM {DB_TABLE_NAME}
                    WHERE label_name = ? 
                    AND confidence >= ?
                    AND save_time BETWEEN ? AND ?
                    ORDER BY save_time DESC"""
            cursor.execute(sql, (
                target_en,
                MIN_DETECTION_CONFIDENCE,
                search_start,
                search_end
            ))
            rows = cursor.fetchall()

            if not rows:
                if start_time:
                    raise Exception(f"åœ¨ {start_time} åˆ° {end_time} æœŸé—´æœªæ‰¾åˆ°ã€{target_cn}ã€‘æ•°æ®")
                else:
                    raise Exception(f"è¡¨{DB_TABLE_NAME}ä¸­æ— ã€{target_cn}ã€‘72å°æ—¶æœ‰æ•ˆæ•°æ®")

            # æŒ‰image_idå»é‡
            image_id_set = set()
            for row in rows:
                image_id = row["image_id"]
                original_path = row["original_path"].strip() if row["original_path"] else ""
                if image_id in image_id_set or not original_path or not os.path.exists(original_path):
                    continue
                image_id_set.add(image_id)

                matched_data.append({
                    "time_str": row["save_time"].strip(),
                    "x": float(row["cam_x"]) if row["cam_x"] else 0.0,
                    "y": float(row["cam_y"]) if row["cam_y"] else 0.0,
                    "z": float(row["cam_z"]) if row["cam_z"] else 0.0,
                    "confidence": float(row["confidence"]) if row["confidence"] else 0.0,
                    "path": original_path
                })

            if not matched_data:
                raise Exception(f"è¯¥æ—¶æ®µå†…ã€{target_cn}ã€‘æ— æœ‰æ•ˆå»é‡æ•°æ®")

        except sqlite3.Error as e:
            raise Exception(f"è¡¨{DB_TABLE_NAME}æ“ä½œå¤±è´¥: {str(e)[:50]}")
        finally:
            if conn:
                conn.close()

        self.get_logger().info(f"âœ… ç®€å•ç›®æ ‡æ£€ç´¢å®Œæˆï¼šç›®æ ‡ã€{target_cn}ã€‘| æœ‰æ•ˆæ•°æ®{len(matched_data)}æ¡")
        return matched_data

    # ---------------------- ç®€å•ç›®æ ‡æ£€ç´¢æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼ˆå‡çº§ç‰ˆï¼‰----------------------
    def _handle_simple_target_retrieval(self, user_question: str, target_cn: str, start_time=None, end_time=None) -> str:
        """ç®€å•ç›®æ ‡æ£€ç´¢æ ¸å¿ƒå¤„ç†ï¼šæŸ¥è¯¢å†å²æ•°æ®+å¤§æ¨¡å‹æ¨ç†"""
        
        time_desc = f"åœ¨ {start_time} åˆ° {end_time} æœŸé—´" if start_time else "æœ€è¿‘72å°æ—¶å†…"
        self.get_logger().info(f"ğŸ” å¤„ç†ç®€å•ç›®æ ‡æ£€ç´¢ï¼šç›®æ ‡ã€{target_cn}ã€‘ï¼ŒèŒƒå›´ï¼š{time_desc}...")
        
        try:
            # ä¼ å…¥æ—¶é—´å‚æ•°
            clip_target_data = self._filter_clip_target_data(target_cn, start_time, end_time)
            if not clip_target_data:
                return f"âŒ {time_desc}æœªæ£€æµ‹åˆ°ç›®æ ‡ã€{target_cn}ã€‘çš„ç›¸å…³æ•°æ®"
            
            clip_data_json = json.dumps(clip_target_data, ensure_ascii=False, indent=2)
            
            prompt = f"""ä½ æ˜¯æ™ºèƒ½æœºå™¨äººè®°å¿†åŠ©æ‰‹ï¼Œè´Ÿè´£å›ç­”ç”¨æˆ·ã€Œæ˜¯å¦è§è¿‡æŸç›®æ ‡ã€çš„ç®€å•æ£€ç´¢é—®é¢˜ã€‚
è¯·ä»…åŸºäºä¸‹æ–¹æä¾›çš„ã€å†å²æ£€æµ‹æ•°æ®ã€‘è¿›è¡Œæ¨ç†ï¼š
æ•°æ®æ—¶é—´èŒƒå›´ï¼š{time_desc}

è§„åˆ™ï¼š
1. æ•°æ®è§£è¯»ï¼štime_str=æ£€æµ‹æ—¶é—´ï¼Œx/y/z=ç›¸å¯¹ç›¸æœº3Dåæ ‡ï¼Œconfidence=æ£€æµ‹ç½®ä¿¡åº¦ï¼Œpath=å›¾åƒè·¯å¾„ï¼›
2. å›ç­”è¦æ±‚ï¼šå£è¯­åŒ–ã€ç®€æ´æ˜äº†ï¼Œè¯´æ˜æ˜¯å¦è§è¿‡+æœ€è¿‘ä¸€æ¬¡å‡ºç°çš„æ—¶é—´/å¤§è‡´ä½ç½®ï¼›
3. ç¦æ­¢è¾“å‡ºJSONã€ä»£ç ï¼Œä¸è‡†é€ ä¿¡æ¯ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_question}
ç›®æ ‡ï¼š{target_cn}
å†å²æ£€æµ‹æ•°æ®ï¼š
{clip_data_json}"""
            
            response = MultiModalConversation.call(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": [{"text": prompt}]}],
                temperature=TEMPERATURE,
                max_tokens=MAX_TOKENS_INFER
            )
            
            if response.status_code != 200:
                raise Exception(f"å¤§æ¨¡å‹æ¨ç†å¤±è´¥: {response.message[:60]}")
            
            llm_answer = response.output.choices[0].message.content[0]["text"].strip()
            self.get_logger().info(f"âœ… ç®€å•ç›®æ ‡æ£€ç´¢å®Œæˆï¼Œå›ç­”ï¼š{llm_answer[:100]}...")
            return llm_answer if llm_answer else f"{time_desc}è§è¿‡ç›®æ ‡ã€{target_cn}ã€‘ï¼Œå…·ä½“ä¿¡æ¯å¯æŸ¥çœ‹å†å²æ•°æ®"
        
        except Exception as e:
            err_msg = str(e)[:80]
            self.get_logger().error(f"âŒ ç®€å•ç›®æ ‡æ£€ç´¢å¤±è´¥ï¼š{err_msg}")
            return f"âŒ æ£€ç´¢ç›®æ ‡ã€{target_cn}ã€‘å¤±è´¥ï¼š{err_msg}"

    # ---------------------- 4ï¼‰é€šç”¨ç›®æ ‡ç­›é€‰ï¼ˆæ·±åº¦æ£€ç´¢ç”¨ï¼Œæ”¯æŒæ—¶é—´è¿‡æ»¤ï¼‰----------------------
    def _filter_target_imgs_with_pose(self, target_cn, start_time=None, end_time=None):
        """æ·±åº¦æ£€ç´¢ä¸“ç”¨ï¼šæ—¶ç©ºèšç±»å»é‡ï¼Œæ”¯æŒè‡ªå®šä¹‰æ—¶é—´æ®µ"""
        raw_items = [] 
        now = datetime.now()
        
        # ç¡®å®šæ—¶é—´çª—å£
        if start_time and end_time:
            search_start = start_time
            search_end = end_time
            # æ ¡éªŒæ—¶é—´æ ¼å¼é˜²æ­¢å´©æºƒ
            try:
                ts_start = parser.parse(search_start)
                ts_end = parser.parse(search_end)
            except:
                ts_start = now - timedelta(hours=TIME_WINDOW_HOURS)
                ts_end = now
        else:
            search_start = (now - timedelta(hours=TIME_WINDOW_HOURS)).strftime('%Y-%m-%d %H:%M:%S')
            search_end = now.strftime('%Y-%m-%d %H:%M:%S')
            ts_start = now - timedelta(hours=TIME_WINDOW_HOURS)
            ts_end = now

        target_en = COCO80_CN2EN[target_cn]
        conn = None
        try:
            conn = sqlite3.connect(DB_FILE_PATH)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            sql = f"""SELECT save_time, label_name, confidence, cam_x, cam_y, cam_z, original_path 
                    FROM {DB_TABLE_NAME} 
                    WHERE label_name = ? AND confidence >= ?
                    AND save_time BETWEEN ? AND ?
                    ORDER BY save_time DESC"""
            cursor.execute(sql, (
                target_en,
                MIN_DETECTION_CONFIDENCE,
                search_start,
                search_end
            ))
            rows = cursor.fetchall()

            if not rows:
                raise Exception(f"è¯¥æ—¶æ®µå†…æ— ã€{target_cn}ã€‘æœ‰æ•ˆæ•°æ®")

            for row in rows:
                path = row["original_path"].strip() if row["original_path"] else ""
                if not path or not os.path.exists(path): continue
                
                time_str = row["save_time"].strip()
                try:
                    ts = parser.parse(time_str)
                    # äºŒæ¬¡æ ¡éªŒæ—¶é—´æˆ³ï¼ˆDBå·²è¿‡æ»¤ï¼Œä½†parseréœ€ç¡®ä¿æ ¼å¼æ­£ç¡®ï¼‰
                    if ts < ts_start or ts > ts_end: continue
                except: continue

                conf = float(row["confidence"])
                
                raw_items.append({
                    "time_str": time_str,
                    "timestamp": ts.timestamp(),
                    "x": float(row["cam_x"]), 
                    "y": float(row["cam_y"]), 
                    "z": float(row["cam_z"]),
                    "confidence": conf,
                    "path": path
                })

        except sqlite3.Error as e:
            raise Exception(f"è¡¨{DB_TABLE_NAME}æ“ä½œå¤±è´¥: {str(e)[:50]}")
        finally:
            if conn: conn.close()

        if not raw_items:
            raise Exception(f"è¯¥æ—¶æ®µå†…æ— æœ‰æ•ˆå›¾ç‰‡æ•°æ®")

        # æ—¶ç©ºèšç±»å»é‡ï¼š0.5ç§’å†…çš„é‡å¤æ•°æ®åªå–ä¸€å¼ 
        TIME_TOLERANCE = 0.5
        clustered_items = []
        current_group = [raw_items[0]]
        
        for i in range(1, len(raw_items)):
            prev_item = raw_items[i-1]
            curr_item = raw_items[i]
            time_diff = abs(prev_item["timestamp"] - curr_item["timestamp"])
            
            if time_diff <= TIME_TOLERANCE:
                current_group.append(curr_item)
            else:
                best_item = max(current_group, key=lambda x: x["confidence"])
                clustered_items.append(best_item)
                current_group = [curr_item]
        
        if current_group:
            best_item = max(current_group, key=lambda x: x["confidence"])
            clustered_items.append(best_item)

        self.get_logger().info(f"âš¡ æ•°æ®å‹ç¼©ä¼˜åŒ–ï¼šåŸå§‹{len(raw_items)}æ¡ -> é‡‡æ ·å{len(clustered_items)}æ¡")
        return clustered_items
    
    # ---------------------- è§†è§‰ç†è§£ä¸šåŠ¡å¤„ç†å‡½æ•°ï¼ˆå…¼å®¹èƒŒæ™¯å›¾ï¼Œä¿ç•™åŸæœ‰ï¼‰----------------------
    def _handle_visual_understanding(self, user_question: str) -> str:
        """è§†è§‰ç†è§£ï¼šç»“åˆå½“å‰å®æ—¶å›¾åƒBase64+ç»“æ„åŒ–æ•°æ®åšå¤šæ¨¡æ€æ¨ç†"""
        self.get_logger().info("ğŸ” å¤„ç†è§†è§‰ç†è§£ï¼šè·å–å½“å‰å®æ—¶åœºæ™¯æ•°æ®+å›¾åƒ...")

        current_data = self.get_common_current_data()
        if not current_data:
            return "âŒ æ— æ³•è·å–å½“å‰ç”»é¢æ•°æ®ï¼Œè¯·æ£€æŸ¥æ‘„åƒå¤´æˆ–æ•°æ®æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚"

        query_img_path = current_data["query_img_path"]
        target_categories = current_data["target_categories"]
        target_xyz = current_data["target_xyz"]

        # æ„é€ å½“å‰åœºæ™¯ç»“æ„åŒ–ä¿¡æ¯
        current_scene_info = {
            "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "detected_objects": target_categories if target_categories else ["æ— ä»»ä½•æœ‰æ•ˆç›®æ ‡"],
            "object_xyz_coords": target_xyz if target_xyz else ["æ— ç›®æ ‡åæ ‡ï¼ˆèƒŒæ™¯å›¾ï¼‰"],
        }
        current_info_json = json.dumps(current_scene_info, ensure_ascii=False, indent=2)

        # å½“å‰å›¾åƒè½¬Base64
        img_base64 = ""
        try:
            img_base64 = self._img_to_base64(query_img_path)
            self.get_logger().info(f"âœ… å½“å‰å›¾åƒè½¬Base64å®Œæˆï¼š{query_img_path[-50:]}")
        except Exception as e:
            self.get_logger().warning(f"âš ï¸ å½“å‰å›¾åƒè½¬Base64å¤±è´¥ï¼š{str(e)[:50]}ï¼Œå°†ä»…åŸºäºç»“æ„åŒ–æ•°æ®æ¨ç†")

        # æ„é€ å¤šæ¨¡æ€Prompt
        prompt = f"""ä½ æ˜¯æœºå™¨äººçš„è§†è§‰ç†è§£åŠ©æ‰‹ï¼Œè´Ÿè´£çœŸå®æè¿°å½“å‰ç”»é¢çœ‹åˆ°çš„å†…å®¹ï¼Œå›ç­”ç”¨æˆ·å…³äºâ€œç°åœ¨çœ‹åˆ°äº†ä»€ä¹ˆâ€çš„é—®é¢˜ã€‚
    è¯·ä¸¥æ ¼éµå®ˆè§„åˆ™ï¼š
    1. ä¼˜å…ˆç»“åˆ**å›¾åƒè§†è§‰ä¿¡æ¯**æè¿°ç”»é¢ï¼Œå†è¡¥å……**ç»“æ„åŒ–æ•°æ®**ä¸­çš„ç›®æ ‡3Dåæ ‡ï¼›
    2. æè¿°è¦æ±‚ï¼šè‡ªç„¶ã€å£è¯­åŒ–ã€ç®€æ´ï¼Œå…ˆè®²æ•´ä½“åœºæ™¯ï¼Œå†è®²å…·ä½“ç›®æ ‡ï¼›
    3. è‹¥å›¾åƒè½¬ç å¤±è´¥/æ— å›¾åƒä¿¡æ¯ï¼Œä»…åŸºäºç»“æ„åŒ–æ•°æ®æè¿°ï¼›
    4. è‹¥ä¸ºèƒŒæ™¯å›¾ï¼ˆæ— ä»»ä½•ç›®æ ‡ï¼‰ï¼Œç›´æ¥è¯´â€œå½“å‰ç”»é¢åªæœ‰èƒŒæ™¯ï¼Œæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•æœ‰æ•ˆç›®æ ‡â€ï¼›
    5. ç¦æ­¢ç¼–é€ ä¿¡æ¯ï¼Œä¸è¾“å‡ºJSON/ä»£ç /ä¸“ä¸šæœ¯è¯­ï¼Œé€‚é…æœºå™¨äººå£è¯­äº¤æµã€‚

    ã€å½“å‰å®æ—¶åœºæ™¯ç»“æ„åŒ–æ•°æ®ã€‘
    {current_info_json}

    ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š{user_question}"""

        # æ„é€ å¤šæ¨¡æ€è¯·æ±‚å†…å®¹
        content = [{"text": prompt}]
        if img_base64:
            ext = os.path.splitext(query_img_path)[1].lower().replace('.', '')
            img_format = ext if ext in ["jpg", "jpeg", "png"] else "jpg"
            content.append({"image": f"data:image/{img_format};base64,{img_base64}"})

        self.get_logger().info("ğŸ’¬ è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€è§†è§‰ç†è§£æ¨ç†...")
        infer_start = time.time()

        # è°ƒç”¨é€šä¹‰åƒé—®å¤šæ¨¡æ€æ¥å£
        response = MultiModalConversation.call(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": content}],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS_CURRENT_SCENE
        )

        infer_cost = round(time.time() - infer_start, 3)
        if response.status_code != 200:
            err_msg = f"è§†è§‰ç†è§£å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {response.message[:60]}"
            self.get_logger().error(f"âŒ {err_msg}ï¼Œè€—æ—¶{infer_cost}s")
            return f"è§†è§‰ç†è§£å¤±è´¥ï¼š{err_msg}"

        llm_answer = response.output.choices[0].message.content[0]["text"].strip()
        if not llm_answer:
            llm_answer = "å½“å‰ç”»é¢ä¸­æœªè¯†åˆ«åˆ°æ˜ç¡®ç›®æ ‡ï¼Œåªæœ‰èƒŒæ™¯ã€‚"

        self.get_logger().info(f"âœ… è§†è§‰ç†è§£å®Œæˆï¼Œè€—æ—¶{infer_cost}s | å›ç­”ï¼š{llm_answer[:100]}...")
        return llm_answer

    # ---------------------- åŸºç¡€å·¥å…·å‡½æ•°ï¼šå›¾åƒè½¬Base64ï¼ˆä¿ç•™åŸæœ‰ï¼‰----------------------
    def _img_to_base64(self, img_path):
        """å›¾åƒè½¬Base64ï¼Œå¸¦è·¯å¾„æ ¡éªŒå’Œä¸Šä¸‹æ–‡å…³é—­"""
        if not os.path.exists(img_path):
            raise Exception(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path[-50:]}")
        try:
            with open(img_path, "rb") as f:
                return base64.b64encode(f.read()).decode("utf-8")
        except Exception as e:
            raise Exception(f"å›¾åƒè¯»å–å¤±è´¥ {img_path[-50:]}: {str(e)[:50]}")

    # ---------------------- æ·±åº¦æ•°æ®èåˆï¼ˆå…¼å®¹ç©ºç±»åˆ«/ç©ºXYZï¼Œä¿ç•™åŸæœ‰ï¼‰----------------------
    def _fusion_depth_data(self, current_data: Dict[str, Any], history_depth_items: List[Dict[str, Any]], target_cn: str) -> Dict[str, Any]:
        """æ·±åº¦å½“å‰åœºæ™¯ä¸“ç”¨ï¼šèåˆå½“å‰å®æ—¶æ•°æ® + æ·±åº¦æ£€ç´¢å†å²åŸå§‹æ•°æ®"""
        current_target_xyz = None
        if current_data["target_categories"]:
            for idx, cat in enumerate(current_data["target_categories"]):
                cat_clean = cat.strip().lower()
                if cat_clean == target_cn:
                    current_target_xyz = current_data["target_xyz"][idx] if idx < len(current_data["target_xyz"]) else None
                    break

        current_status = "æœ‰ç›®æ ‡" if current_target_xyz else "æ— ç›®æ ‡ï¼ˆèƒŒæ™¯å›¾/æœªæ£€æµ‹åˆ°ï¼‰"
        self.get_logger().info(f"ğŸ“Š å½“å‰ç›®æ ‡çŠ¶æ€ï¼šã€{target_cn}ã€‘{current_status}")

        history_sorted = sorted(history_depth_items, key=lambda x: x["time_str"], reverse=True) if history_depth_items else []
        fusion_data = {
            "target_cn": target_cn,
            "current_data": {
                "query_img_path": current_data["query_img_path"],
                "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
                "current_xyz": current_target_xyz if current_target_xyz else [],
                "current_scene_categories": current_data["target_categories"] if current_data["target_categories"] else ["æ— æœ‰æ•ˆç›®æ ‡ï¼ˆèƒŒæ™¯å›¾ï¼‰"],
                "current_target_status": current_status
            },
            "history_depth_data": history_sorted,
            "history_data_count": len(history_depth_items),
            "time_window_hours": TIME_WINDOW_HOURS,
            "min_detection_confidence": MIN_DETECTION_CONFIDENCE
        }

        self.get_logger().info(f"âœ… æ·±åº¦æ•°æ®èåˆå®Œæˆï¼šç›®æ ‡ã€{target_cn}ã€‘| å½“å‰çŠ¶æ€{current_status} | å†å²æœ‰æ•ˆæ•°æ®{len(history_depth_items)}æ¡")
        return fusion_data

    # ---------------------- ğŸ”¥ æ ¸å¿ƒé‡æ„ï¼šæ·±åº¦å½“å‰åœºæ™¯8å¼ å›¾å•æ‰¹æ¬¡æ¨ç†ï¼ˆåˆ é™¤æ‰€æœ‰åˆ†æ‰¹/èåˆé€»è¾‘ï¼‰----------------------
    def _handle_depth_current_scene(self, user_question: str, target_cn: str) -> str:
        """
        æ·±åº¦å½“å‰åœºæ™¯æ ¸å¿ƒé€»è¾‘ï¼š1å¼ å½“å‰å›¾ + 7å¼ å†å²æœ€æ–°å›¾ = 8å¼ ï¼Œ**å•æ‰¹æ¬¡ç›´æ¥è°ƒç”¨å¤§æ¨¡å‹**
        å®Œå…¨åˆ é™¤åˆ†æ‰¹æ¬¡ã€å¤šçº¿ç¨‹ã€æ‰¹æ¬¡ç»“æœèåˆé€»è¾‘ï¼Œæµç¨‹æç®€ï¼šå–å›¾â†’è½¬ç â†’å•è¯·æ±‚â†’è¿”å›ç»“æœ
        """
        self.get_logger().info(f"ğŸ” å¼€å§‹å¤„ç†æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜ï¼Œç›®æ ‡ã€{target_cn}ã€‘| å›ºå®šè§„åˆ™ï¼š1å¼ å½“å‰+7å¼ å†å²=8å¼ ï¼Œå•æ‰¹æ¬¡æ¨ç†...")
        try:
            # æ­¥éª¤1ï¼šè·å–å½“å‰å®æ—¶æ•°æ®ï¼ˆæ— å›¾åƒç›´æ¥è¿”å›å¤±è´¥ï¼‰
            current_data = self.get_common_current_data()
            if not current_data or not current_data.get("query_img_path") or not os.path.exists(current_data["query_img_path"]):
                err_msg = "âŒ æ— æ³•å¤„ç†ï¼šè°ƒç”¨ROS2æœåŠ¡è·å–å½“å‰å®æ—¶å›¾åƒå¤±è´¥ï¼ˆæ— æœ‰æ•ˆè·¯å¾„ï¼‰"
                self.get_logger().error(err_msg)
                return err_msg
            current_img_path = current_data["query_img_path"]
            self.get_logger().info(f"âœ… å·²è·å–å½“å‰å®æ—¶å›¾åƒï¼š{current_img_path[-60:]}")

            # æ­¥éª¤2ï¼šç­›é€‰ç›®æ ‡å†å²æ·±åº¦æ•°æ®ï¼ˆæ— æ•°æ®åˆ™å…¼å®¹ï¼Œå†å²å›¾è¡¥0ï¼‰
            history_depth_items = []
            try:
                history_depth_items = self._filter_target_imgs_with_pose(target_cn)
            except Exception as e:
                self.get_logger().warning(f"âš ï¸ æ— ç›®æ ‡ã€{target_cn}ã€‘å†å²æ•°æ®ï¼š{str(e)[:60]}ï¼Œå°†ä»…ä½¿ç”¨å½“å‰1å¼ å›¾æ¨ç†")

            # æ­¥éª¤3ï¼šèåˆå½“å‰+å†å²ç»“æ„åŒ–æ•°æ®
            fusion_data = self._fusion_depth_data(current_data, history_depth_items, target_cn)
            fusion_data_json = json.dumps(fusion_data, ensure_ascii=False, indent=2)

            # æ­¥éª¤4ï¼šå›ºå®šå–å›¾ - 1å¼ å½“å‰ + 7å¼ å†å²æœ€æ–°ï¼ˆè‡ªåŠ¨è¡¥å…¨/æˆªæ–­ï¼‰
            # 4.1 æå–å†å²æœ‰æ•ˆå›¾åƒè·¯å¾„ï¼ˆå»é‡ã€è¿‡æ»¤æ— æ•ˆï¼‰
            history_img_paths = []
            for item in history_depth_items:
                if item and "path" in item and item["path"] and os.path.exists(item["path"]):
                    history_img_paths.append(item["path"])
            # 4.2 å†å²å›¾åªå–æœ€æ–°7å¼ ï¼Œä¸è¶³åˆ™å–å…¨éƒ¨ï¼Œè‡ªåŠ¨å»é‡
            history_img_paths = history_img_paths[:FIXED_HISTORY_IMG]  # æˆªæ–­ä¸º7å¼ 
            history_img_paths = list(dict.fromkeys(history_img_paths))  # å»é‡
            # 4.3 åˆå¹¶ï¼š1å¼ å½“å‰ + 7å¼ å†å²ï¼ˆæ€»å¼ æ•°å›ºå®šâ‰¤8ï¼‰
            total_img_paths = [current_img_path] + history_img_paths
            self.get_logger().info(f"âœ… å›ºå®šå–å›¾å®Œæˆ | å½“å‰å›¾ï¼š1å¼  | å†å²å›¾ï¼š{len(history_img_paths)}å¼  | æ€»å¼ æ•°ï¼š{len(total_img_paths)}å¼ ")

            # æ­¥éª¤5ï¼šæ„é€ å•æ‰¹æ¬¡å¤šæ¨¡æ€è¯·æ±‚ï¼ˆæ–‡æœ¬Prompt + 8å¼ å›¾Base64ï¼‰
            request_content = self._build_single_batch_content(user_question, fusion_data_json, total_img_paths)
            if not request_content:
                err_msg = "âŒ æ„é€ å¤šæ¨¡æ€è¯·æ±‚å¤±è´¥ï¼šæ— æœ‰æ•ˆæ–‡æœ¬/å›¾åƒæ•°æ®"
                self.get_logger().error(err_msg)
                return err_msg

            # æ­¥éª¤6ï¼šå•æ‰¹æ¬¡è°ƒç”¨å¤§æ¨¡å‹ï¼ˆæ ¸å¿ƒï¼šä¸€æ¬¡è¯·æ±‚è§£å†³ï¼Œæ— åˆ†æ‰¹ï¼‰
            self.get_logger().info(f"ğŸ’¬ å•æ‰¹æ¬¡è°ƒç”¨å¤§æ¨¡å‹æ¨ç†ï¼ˆ{len(total_img_paths)}å¼ å›¾ï¼‰...")
            infer_start = time.time()
            final_answer = self._call_qwen_single_batch(request_content)
            infer_cost = round(time.time() - infer_start, 3)

            if final_answer == "æ¨ç†å¤±è´¥":
                # å…œåº•ï¼šä½¿ç”¨ç»“æ„åŒ–æ•°æ®ç”Ÿæˆå›ç­”
                final_answer = self._get_default_answer(fusion_data)
            self.get_logger().info(f"âœ… æ·±åº¦å½“å‰åœºæ™¯å•æ‰¹æ¬¡æ¨ç†å®Œæˆ | è€—æ—¶{infer_cost}s | å›ç­”ï¼š{final_answer[:100]}...")
            return final_answer

        except Exception as e:
            err_msg = str(e)[:150]
            self.get_logger().error(f"âŒ æ·±åº¦å½“å‰åœºæ™¯å¤„ç†å¼‚å¸¸ï¼š{err_msg}")
            return f"âŒ æ·±åº¦åœºæ™¯å¤„ç†å¤±è´¥ï¼š{err_msg}"

    # ---------------------- è¾…åŠ©ï¼šæ„é€ å•æ‰¹æ¬¡è¯·æ±‚å†…å®¹ï¼ˆæ–‡æœ¬+å¤šå¼ å›¾ï¼‰----------------------
    def _build_single_batch_content(self, user_question, fusion_data_json, img_paths):
        """æ„é€ å•æ‰¹æ¬¡å¤šæ¨¡æ€è¯·æ±‚å†…å®¹ï¼šPromptæ–‡æœ¬ + æ‰€æœ‰å›¾åƒBase64"""
        try:
            # æ·±åº¦å½“å‰åœºæ™¯ä¸“ç”¨Promptï¼ˆå¼•å¯¼å¤§æ¨¡å‹ç»“åˆå›¾åƒ+ç»“æ„åŒ–æ•°æ®æ¨ç†ï¼‰
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„æœºå™¨äººæ·±åº¦åœºæ™¯åˆ†æä¸“å®¶ï¼Œè´Ÿè´£å›ç­”å¸¦ç‰¹å¾ç›®æ ‡çš„**å»å‘ã€æ˜¯å¦è¢«æ‹¿èµ°ã€ä½ç½®å˜åŒ–ã€æ˜¯å¦ç§»åŠ¨**ç­‰æ ¸å¿ƒé—®é¢˜ã€‚
ä»¥ä¸‹æ˜¯ã€å…¨å±€ç»“æ„åŒ–èåˆæ•°æ®ã€‘å’Œ{len(img_paths)}å¼ å›¾åƒï¼ˆç¬¬1å¼ =å½“å‰å®æ—¶å›¾ï¼Œåç»­=å†å²æœ€æ–°å›¾ï¼‰ï¼Œè¯·ç»“åˆå›¾åƒè§†è§‰ä¿¡æ¯+ç»“æ„åŒ–æ•°æ®æ·±åº¦æ¨ç†ï¼
=== æ ¸å¿ƒæ¨ç†ä¾æ® ===
{fusion_data_json}
=== ç”¨æˆ·æ ¸å¿ƒé—®é¢˜ ===
{user_question}
=== ä¸¥æ ¼å›ç­”è§„åˆ™ ===
1. ä¼˜å…ˆç»“åˆå›¾åƒè§†è§‰ç‰¹å¾ï¼ˆå¦‚ç›®æ ‡é¢œè‰²/å½¢çŠ¶/äººç‰©æ“ä½œï¼‰+ 3Dåæ ‡åˆ†æï¼›
2. æ˜ç¡®åˆ¤å®šç›®æ ‡ã€Œæ˜¯å¦è¢«æ‹¿èµ°/æ˜¯å¦åœ¨å½“å‰è§†é‡/å½“å‰3Dåæ ‡/æœ€åå‡ºç°ä½ç½®ã€ï¼›
3. å›ç­”å£è¯­åŒ–ã€ç®€æ´æ˜äº†ï¼Œé€‚é…æœºå™¨äººç»ˆç«¯ï¼Œä¸è¾“å‡ºJSON/ä»£ç /ä¸“ä¸šæœ¯è¯­ï¼›
4. æ— æœ‰æ•ˆä¿¡æ¯æ—¶ç›´æ¥è¯´æ˜ï¼Œä¸è‡†é€ ä»»ä½•å†…å®¹ã€‚"""
            
            # æ„é€ è¯·æ±‚ï¼šå…ˆæ–‡æœ¬ï¼Œå†é€å¼ è½¬Base64åŠ å›¾åƒ
            content = [{"text": prompt}]
            for idx, img_path in enumerate(img_paths, 1):
                try:
                    b64 = self._img_to_base64(img_path)
                    ext = os.path.splitext(img_path)[1].lower().replace('.', '')
                    img_format = ext if ext in ["jpg", "jpeg", "png"] else "jpg"
                    content.append({"image": f"data:image/{img_format};base64,{b64}"})
                    self.get_logger().debug(f"âœ… ç¬¬{idx}å¼ å›¾è½¬Base64å®Œæˆï¼š{img_path[-30:]}")
                except Exception as e:
                    self.get_logger().warning(f"âš ï¸ ç¬¬{idx}å¼ å›¾è½¬ç å¤±è´¥ï¼š{img_path[-30:]} | {str(e)[:40]}")
                    continue

            return content if len(content) >= 1 else None
        except Exception as e:
            self.get_logger().error(f"âŒ æ„é€ è¯·æ±‚å†…å®¹å¤±è´¥ï¼š{str(e)[:60]}")
            return None

    # ---------------------- è¾…åŠ©ï¼šå•æ‰¹æ¬¡è°ƒç”¨å¤§æ¨¡å‹ï¼ˆé€šä¹‰åƒé—®å¤šæ¨¡æ€ï¼‰----------------------
    def _call_qwen_single_batch(self, content):
        """å•æ‰¹æ¬¡è°ƒç”¨é€šä¹‰åƒé—®å¤šæ¨¡æ€æ¥å£ï¼Œè¿”å›æ¨ç†ç»“æœ"""
        try:
            response = MultiModalConversation.call(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": content}],
                temperature=TEMPERATURE,
                max_tokens=MAX_TOKENS_DEPTH_CURRENT
            )
            if response.status_code != 200:
                self.get_logger().error(f"âŒ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼šçŠ¶æ€ç {response.status_code} | {response.message[:60]}")
                return "æ¨ç†å¤±è´¥"
            answer = response.output.choices[0].message.content[0]["text"].strip()
            return answer if answer else "æ¨ç†å¤±è´¥"
        except Exception as e:
            self.get_logger().error(f"âŒ å¤§æ¨¡å‹è°ƒç”¨å¼‚å¸¸ï¼š{str(e)[:80]}")
            return "æ¨ç†å¤±è´¥"

    # ---------------------- è¾…åŠ©ï¼šç»“æ„åŒ–æ•°æ®å…œåº•å›ç­”ï¼ˆå¤§æ¨¡å‹æ¨ç†å¤±è´¥æ—¶ç”¨ï¼‰----------------------
    def _get_default_answer(self, fusion_data):
        """åŸºäºç»“æ„åŒ–èåˆæ•°æ®ç”Ÿæˆå…œåº•å›ç­”ï¼Œé¿å…æ— ç»“æœ"""
        target_cn = fusion_data["target_cn"]
        current_status = fusion_data["current_data"]["current_target_status"]
        history_count = fusion_data["history_data_count"]
        current_xyz = fusion_data["current_data"]["current_xyz"]
        history_data = fusion_data["history_depth_data"]

        if current_status == "æœ‰ç›®æ ‡":
            return f"âœ… ç›®æ ‡ã€{target_cn}ã€‘å½“å‰ç”»é¢å¯æ£€æµ‹åˆ°ï¼Œç›¸å¯¹ç›¸æœº3Dåæ ‡ï¼šX={current_xyz[0]:.2f}ã€Y={current_xyz[1]:.2f}ã€Z={current_xyz[2]:.2f}ï¼"
        elif current_status == "æ— ç›®æ ‡" and history_count > 0:
            last = history_data[0]
            last_time = last.get("time_str", "æœªçŸ¥æ—¶é—´")
            last_xyz = f"X={last.get('x',0):.2f}ã€Y={last.get('y',0):.2f}ã€Z={last.get('z',0):.2f}"
            return f"âŒ ç›®æ ‡ã€{target_cn}ã€‘å½“å‰æœªæ£€æµ‹åˆ°ï¼Œæœ€åä¸€æ¬¡åœ¨{last_time}å‡ºç°åœ¨{last_xyz}ï¼Œåˆ¤æ–­å·²è¢«æ‹¿èµ°/ç§»å‡ºè§†é‡ï¼"
        else:
            return f"âš ï¸  ç›®æ ‡ã€{target_cn}ã€‘å½“å‰æœªæ£€æµ‹åˆ°ï¼Œä¸”è¿‘72å°æ—¶æ— å†å²å‡ºç°è®°å½•ï¼Œæ— æ³•åˆ¤æ–­çŠ¶æ€ï¼"

    # ---------------------- æ·±åº¦ç›®æ ‡æ£€ç´¢åŸæœ‰é€»è¾‘ï¼ˆä¿ç•™ï¼Œæœªä¿®æ”¹ï¼‰----------------------
    def _infer_single_batch(self, user_question, batch_items, batch_idx, total_batch, target_cn):
        batch_start = time.time()
        content = []
        item_desc_list = []
        for i, item in enumerate(batch_items):
            desc = (f"å›¾{i+1}ï¼šæ—¶é—´={item['time_str']}ï¼Œç›¸å¯¹ç›¸æœºä½ç½® X={item['x']:.3f} Y={item['y']:.3f} Z={item['z']:.3f}ï¼Œæ£€æµ‹ç½®ä¿¡åº¦={item['confidence']:.3f}")
            item_desc_list.append(desc)
        item_desc_str = "\n".join(item_desc_list)

        prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{user_question}ï¼ˆå¸¦ç‰¹å¾çš„æ·±åº¦ç›®æ ‡æ£€ç´¢ï¼‰
ä¸‹é¢æ˜¯ä¸€æ‰¹æ£€æµ‹å›¾åƒï¼Œå…±{len(batch_items)}å¼ ï¼Œæ¯å¼ å›¾çš„æ—¶é—´ã€ç›¸å¯¹ç›¸æœº3Dä½ç½®å’Œæ£€æµ‹ç½®ä¿¡åº¦ä¿¡æ¯å¦‚ä¸‹ï¼ˆå·²æŒ‰æ—¶é—´ä»æ—©åˆ°æ™šæ’åºï¼‰ï¼š
{item_desc_str}
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™åˆ†æå¹¶è¾“å‡ºï¼Œ**å¿…é¡»å®Œå…¨éµå®ˆï¼Œä¸åˆå¹¶ã€ä¸åˆ å‡ã€ä¸ä¿®æ”¹ä»»ä½•æ—¶é—´/ä½ç½®åæ ‡ä¿¡æ¯**ï¼š
1. ä»…åŸºäºæä¾›çš„å›¾ç‰‡å’Œä¿¡æ¯åˆ¤æ–­ï¼Œé‡ç‚¹åŒ¹é…ç”¨æˆ·æè¿°çš„ç›®æ ‡ç‰¹å¾ï¼›
2. å¦‚æœæ‰¾åˆ°ç¬¦åˆç‰¹å¾çš„ç›®æ ‡ã€{target_cn}ã€‘ï¼Œ**æ¯ä¸ªç›®æ ‡çš„æ—¶é—´å’Œä½ç½®éƒ½è¦å•ç‹¬æˆè¡Œã€é€æ¡è¾“å‡º**ï¼Œå›ºå®šæ ¼å¼ï¼š
   åœ¨{item['time_str']}ï¼Œç¬¦åˆç‰¹å¾çš„ç›®æ ‡ã€{target_cn}ã€‘å‡ºç°åœ¨ç›¸å¯¹ç›¸æœºä½ç½® X={item['x']:.3f} Y={item['y']:.3f} Z={item['z']:.3f}
3. æ‰€æœ‰ä½ç½®ä¿¡æ¯è¾“å‡ºå®Œæˆåï¼Œå¦èµ·ä¸€è¡Œæ ‡æ³¨ã€Œã€æ¨ç†ã€‘ã€å¹¶åŸºäºç‰¹å¾ã€æ—¶é—´ã€ä½ç½®æ¨ç†åˆ†æé—®é¢˜å¹¶è¾“å‡ºå½“å‰å¯èƒ½ä½ç½®ï¼ˆä¿¡æ¯ä¸è¶³åˆ™è¾“å‡ºã€Œå½“å‰ä½ç½®æ— æ³•åˆ¤æ–­ã€ï¼‰ï¼›
4. å¦‚æœæœªæ‰¾åˆ°ç¬¦åˆç‰¹å¾çš„ç›®æ ‡ã€{target_cn}ã€‘ï¼Œä»…è¾“å‡ºï¼šæœ¬æ‰¹æ¬¡æœªæ‰¾åˆ°ç¬¦åˆç‰¹å¾çš„ç›®æ ‡ï¼Œæ— å…¶ä»–ä»»ä½•å†…å®¹ã€‚
è¾“å‡ºè¦æ±‚ï¼šæ— é¢å¤–æ–‡å­—ã€æ— åºå·ã€æ— æ ‡é¢˜ï¼Œé€»è¾‘æ¸…æ™°ã€‚"""
        content.append({"text": prompt})

        for item in batch_items:
            b64 = self._img_to_base64(item["path"])
            ext = os.path.splitext(item["path"])[1].lower().replace('.', '')
            img_format = ext if ext in ["jpg", "jpeg", "png"] else "jpg"
            content.append({"image": f"data:image/{img_format};base64,{b64}"})

        response = MultiModalConversation.call(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": content}],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS_INFER
        )

        if response.status_code != 200:
            raise Exception(f"ç¬¬{batch_idx}/{total_batch}æ‰¹æ¬¡æ¨ç†å¤±è´¥: {response.message[:60]}")

        ans = response.output.choices[0].message.content[0]["text"].strip()
        if not ans:
            raise Exception(f"ç¬¬{batch_idx}/{total_batch}æ‰¹æ¬¡è¿”å›ç©ºç»“æœ")

        batch_cost = round(time.time() - batch_start, 3)
        self.get_logger().info(f"âœ… ç¬¬{batch_idx}/{total_batch}æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œè€—æ—¶{batch_cost}s")
        return ans

    def _fusion_batch_results(self, user_question, batch_answers, target_cn):
        fusion_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{user_question}ï¼ˆå¸¦ç‰¹å¾çš„æ·±åº¦ç›®æ ‡æ£€ç´¢ï¼‰
ä¸‹é¢æ˜¯{len(batch_answers)}ä¸ªå›¾ç‰‡æ‰¹æ¬¡çš„åˆ†æç»“æœï¼Œæ‰€æœ‰æ‰¹æ¬¡å·²æŒ‰æ—¶é—´ä»æ—©åˆ°æ™šæ’åºï¼š
{chr(10).join(batch_answers)}
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™æ±‡æ€»æ‰€æœ‰ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œ**å¿…é¡»å®Œå…¨éµå®ˆï¼Œä¸åˆå¹¶ã€ä¸åˆ å‡ã€ä¸ä¿®æ”¹ä»»ä½•æ—¶é—´/ä½ç½®åæ ‡ä¿¡æ¯**ï¼š
1. ç­›é€‰æœ‰æ•ˆä¿¡æ¯ï¼šæå–æ‰€æœ‰ç¬¦åˆã€Œåœ¨xxxx-xx-xx xx:xx:xxï¼Œç¬¦åˆç‰¹å¾çš„ç›®æ ‡ã€{target_cn}ã€‘å‡ºç°åœ¨ç›¸å¯¹ç›¸æœºä½ç½® X=* Y=* Z=*ã€æ ¼å¼çš„è¡Œï¼Œåˆ é™¤æ— æ•ˆè¡Œï¼›
2. æ•´ç†ä½ç½®ä¿¡æ¯ï¼šå°†æ‰€æœ‰æœ‰æ•ˆè¡ŒæŒ‰æ—¶é—´ä»æ—©åˆ°æ™šé‡æ–°æ’åºï¼Œæ¯æ¡ä¿¡æ¯å•ç‹¬å ä¸€è¡Œï¼Œæ— é‡å¤ã€æ— ä¿®æ”¹ï¼›
3. ç”Ÿæˆæœ€ç»ˆæ¨ç†ï¼šæ•´ç†å®Œæ‰€æœ‰ä½ç½®ä¿¡æ¯åï¼Œæ ‡æ³¨ã€Œã€æœ€ç»ˆæ¨ç†ã€‘ã€å¹¶åŸºäºç‰¹å¾ã€ä½ç½®å˜åŒ–ã€æ—¶é—´å…ˆåç»¼åˆåˆ†æç”¨æˆ·é—®é¢˜å¹¶è¾“å‡ºå½“å‰å¯èƒ½ä½ç½®ï¼Œéœ€æœ‰ä¾æ®ï¼›
4. æ— æœ‰æ•ˆä¿¡æ¯æ—¶ï¼Œä»…è¾“å‡ºï¼šæœªæ‰¾åˆ°ç¬¦åˆç‰¹å¾çš„ç›®æ ‡ã€{target_cn}ã€‘ç›¸å…³æ£€æµ‹å›¾åƒä¿¡æ¯ï¼›
5. ç»å¯¹ç¦æ­¢æ·»åŠ åºå·ã€æ ‡é¢˜ã€é¢å¤–è§£é‡Šï¼Œä»…æŒ‰è¦æ±‚è¾“å‡ºç»“æœã€‚"""

        fusion_response = MultiModalConversation.call(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": [{"text": fusion_prompt}]}],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS_FUSION
        )

        if fusion_response.status_code != 200:
            raise Exception(f"ç»“æœèåˆå¤±è´¥: {fusion_response.message[:60]}")

        final_ans = fusion_response.output.choices[0].message.content[0]["text"].strip()
        if not final_ans:
            return f"æœªæ‰¾åˆ°ç¬¦åˆç‰¹å¾çš„ç›®æ ‡ã€{target_cn}ã€‘ç›¸å…³æ£€æµ‹å›¾åƒä¿¡æ¯"
        return final_ans

    def _llm_infer_images_with_pose(self, user_question, items, target_cn):
            batches = [items[i:i+FIXED_TOTAL_IMG] for i in range(0, len(items), FIXED_TOTAL_IMG)]
            total_batch = len(batches)
            self.get_logger().info(f"ğŸ“¤ å…±{len(items)}å¼ æœ‰æ•ˆå›¾åƒï¼Œåˆ‡åˆ†ä¸º{total_batch}æ‰¹æ¬¡è¿›è¡Œæ·±åº¦æ£€ç´¢æ¨ç†")

            batch_answers = [None] * total_batch
            MAX_WORKERS = 6 
            
            from concurrent.futures import ThreadPoolExecutor, as_completed

            self.get_logger().info(f"âš¡ å¯åŠ¨å¤šçº¿ç¨‹åŠ é€Ÿï¼Œå¹¶å‘æ•°: {MAX_WORKERS}...")
            parallel_start = time.time()

            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                future_to_idx = {
                    executor.submit(
                        self._infer_single_batch, 
                        user_question, batch, idx, total_batch, target_cn
                    ): idx 
                    for idx, batch in enumerate(batches, 1)
                }
                
                for future in as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        ans = future.result()
                        batch_answers[idx-1] = ans
                    except Exception as e:
                        err_msg = f"ï¼ˆç¬¬{idx}æ‰¹æ¬¡æ¨ç†å¤±è´¥: {str(e)[:50]}ï¼‰"
                        self.get_logger().error(f"âŒ {err_msg}")
                        batch_answers[idx-1] = err_msg

            batch_answers = [ans for ans in batch_answers if ans]
            cost = time.time() - parallel_start
            self.get_logger().info(f"âš¡ å¹¶å‘æ¨ç†å®Œæˆï¼Œå®é™…è€—æ—¶: {cost:.2f}s")

            final_ans = self._fusion_batch_results(
                user_question=user_question,
                batch_answers=batch_answers,
                target_cn=target_cn
            )
            return final_ans

    # ---------------------- æ— ç›®æ ‡æ—¶çš„é€šç”¨æ±‡æ€»ï¼ˆä¿ç•™åŸæœ‰ï¼‰----------------------
    def _handle_general_summary(self, question):
        """å½“ç”¨æˆ·é—®'çœ‹è§ä»€ä¹ˆäº†'ä¸”æ— å…·ä½“ç›®æ ‡æ—¶ï¼Œæ±‡æ€»æœ€è¿‘1å°æ—¶çš„æ•°æ®"""
        conn = sqlite3.connect(DB_FILE_PATH)
        cursor = conn.cursor()
        now = datetime.now()
        start_time = now - timedelta(hours=1)
        
        try:
            sql = f"""SELECT label_name FROM {DB_TABLE_NAME} 
                    WHERE confidence > {MIN_DETECTION_CONFIDENCE}
                    AND save_time BETWEEN ? AND ?
                    GROUP BY label_name"""
            cursor.execute(sql, (start_time.strftime('%Y-%m-%d %H:%M:%S'), now.strftime('%Y-%m-%d %H:%M:%S')))
            rows = cursor.fetchall()
            
            summary_list = []
            for row in rows:
                label_en = row[0]
                cn_name = COCO80_EN2CN.get(label_en, label_en)
                summary_list.append(cn_name)
            
            conn.close()

            if not summary_list:
                return "åˆšæ‰è¿™ä¸€ä¸ªå°æ—¶é‡Œï¼Œæˆ‘æ²¡çœ‹è§ä»€ä¹ˆç‰¹åˆ«çš„ä¸œè¥¿ã€‚"
            
            prompt = f"ç”¨æˆ·é—®ï¼š'{question}'ã€‚æœ€è¿‘1å°æ—¶æˆ‘çœ‹è§äº†è¿™äº›ä¸œè¥¿ï¼š{', '.join(summary_list)}ã€‚è¯·ç”¨ç®€çŸ­çš„å£è¯­æ±‡æ€»ä¸€ä¸‹ã€‚"
            
            response = MultiModalConversation.call(
                model=MODEL_NAME, messages=[{"role": "user", "content": [{"text": prompt}]}]
            )
            return response.output.choices[0].message.content[0]["text"]
            
        except Exception as e:
            if conn: conn.close()
            return "æ£€ç´¢è®°å¿†æ—¶å‡ºäº†ç‚¹å°å·®é”™ï¼Œèƒ½å†è¯´ä¸€éå—ï¼Ÿ"

    # ---------------------- æ ¸å¿ƒï¼šæŒ‰æ„å›¾å¤„ç†ç­”æ¡ˆï¼ˆæ ¸å¿ƒï¼šä¼ å…¥æ—¶é—´å‚æ•°ï¼‰----------------------
    def _intent_answer(self, intent, user_question, target_cn=None, start_time=None, end_time=None, goal_handle=None, feedback=None):
        """å¤„ç†æ‰€æœ‰æ„å›¾çš„ä¸šåŠ¡é€»è¾‘"""
        if intent == "è§†è§‰ç†è§£":
            self.get_logger().info(f"ğŸ” è§¦å‘è§†è§‰ç†è§£æ„å›¾ï¼Œé—®é¢˜: {user_question[:50]}...")
            return self._handle_visual_understanding(user_question)

        elif intent == "ç®€å•ç›®æ ‡æ£€ç´¢":
            self.get_logger().info(f"ğŸ” è§¦å‘ç®€å•ç›®æ ‡æ£€ç´¢æ„å›¾ï¼Œç›®æ ‡: {target_cn}ï¼Œé—®é¢˜: {user_question[:50]}...")
            return self._handle_simple_target_retrieval(user_question, target_cn, start_time, end_time)

        elif intent == "æ·±åº¦ç›®æ ‡æ£€ç´¢":
            self.get_logger().info(f"ğŸ” è§¦å‘æ·±åº¦ç›®æ ‡æ£€ç´¢æ„å›¾ï¼Œç›®æ ‡: {target_cn}ï¼Œé—®é¢˜: {user_question[:50]}...")
            self.is_depth_retrieving = True
            threading.Thread(
                target=self._depth_retrieval_feedback_thread,
                args=(goal_handle, feedback),
                daemon=True
            ).start()
            try:
                # ä¼ å…¥æ—¶é—´å‚æ•°
                items = self._filter_target_imgs_with_pose(target_cn, start_time, end_time)
                ans = self._llm_infer_images_with_pose(user_question, items, target_cn)
                return ans
            finally:
                self.is_depth_retrieving = False

        elif intent == "ç®€å•å½“å‰åœºæ™¯é—®é¢˜":
            return self._handle_simple_current_scene(user_question)

        elif intent == "æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜":
            self.get_logger().info(f"ğŸ” è§¦å‘æ·±åº¦å½“å‰åœºæ™¯é—®é¢˜ï¼Œç›®æ ‡: {target_cn}ï¼Œé—®é¢˜: {user_question[:50]}...")
            self.is_depth_retrieving = True
            threading.Thread(
                target=self._depth_retrieval_feedback_thread,
                args=(goal_handle, feedback),
                daemon=True
            ).start()
            try:
                return self._handle_depth_current_scene(user_question, target_cn)
            finally:
                self.is_depth_retrieving = False

        elif intent == "é—²èŠ":
            self.get_logger().info(f"ğŸ’¬ è§¦å‘é—²èŠæ„å›¾ï¼Œç”¨æˆ·é—®é¢˜: {user_question[:50]}...")
            return self._llm_chat(user_question)

        else:
            raise Exception(f"ä¸æ”¯æŒçš„æ„å›¾: {intent}ï¼Œä»…æ”¯æŒ{SUPPORTED_INTENTS}")

    # ---------------------- Action ä¸»å›è°ƒï¼ˆé€‚é…æ‰€æœ‰æ„å›¾ï¼Œå‡çº§å‚æ•°æ¥æ”¶ï¼‰----------------------
    def execute_callback(self, goal_handle):
        self.total_start = time.time()
        user_q = goal_handle.request.user_question.strip()
        feedback = ApiAction.Feedback()
        result = ApiAction.Result()

        self.get_logger().info(f"ğŸ“¥ æ”¶åˆ°å®¢æˆ·ç«¯è¯·æ±‚: {user_q}")

        if not user_q:
            result.success = False
            result.intent = "é—²èŠ"
            result.message = "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ï¼ˆæ”¯æŒæ£€ç´¢/å½“å‰åœºæ™¯/è§†è§‰ç†è§£/é—²èŠï¼‰"
            goal_handle.abort()
            return result

        try:
            # é˜¶æ®µ1ï¼šæ„å›¾åˆ†ç±»ï¼ˆæ¥æ”¶4ä¸ªè¿”å›å€¼ï¼‰
            feedback.feedback_msg = "æ­£åœ¨è¿›è¡Œæ„å›¾ä¸æ—¶é—´è§£æ..."
            feedback.elapsed_time = round(time.time() - self.total_start, 3)
            goal_handle.publish_feedback(feedback)
            
            intent, target_cn, start_time, end_time = self._llm_text_classify(user_q)
            
            time_log = f" | æ—¶é—´ç­›é€‰ï¼š{start_time} è‡³ {end_time}" if start_time else ""
            self.get_logger().info(f"âœ… æ„å›¾åˆ†ç±»å®Œæˆï¼š{intent} | ç›®æ ‡ï¼š{target_cn}{time_log}")

            # é˜¶æ®µ2ï¼šæŒ‰æ„å›¾å¤„ç†ä¸šåŠ¡ï¼ˆä¼ é€’æ‰€æœ‰å‚æ•°ï¼‰
            feedback.feedback_msg = f"æ­£åœ¨{intent}å¤„ç†ä¸­..."
            feedback.elapsed_time = round(time.time() - self.total_start, 3)
            goal_handle.publish_feedback(feedback)
            ans_start = time.time()
            
            final_ans = self._intent_answer(
                intent=intent,
                user_question=user_q,
                target_cn=target_cn,
                start_time=start_time, # æ–°å¢
                end_time=end_time,     # æ–°å¢
                goal_handle=goal_handle,
                feedback=feedback
            )
            
            ans_cost = round(time.time() - ans_start, 3)
            self.get_logger().info(f"âœ… {intent}ä¸šåŠ¡å¤„ç†å®Œæˆï¼Œè€—æ—¶{ans_cost}s")

            # é˜¶æ®µ3ï¼šè¿”å›æœ€ç»ˆç»“æœ
            feedback.feedback_msg = f"{intent}å¤„ç†å®Œæˆï¼Œæ­£åœ¨è¿”å›æœ€ç»ˆç»“æœ..."
            feedback.elapsed_time = round(time.time() - self.total_start, 3)
            goal_handle.publish_feedback(feedback)

            result.success = True
            result.intent = intent
            result.message = final_ans
            goal_handle.succeed()

            total_cost = round(time.time() - self.total_start, 3)
            self.get_logger().info(f"ğŸ‰ æœ¬æ¬¡è¯·æ±‚å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_cost}s\n")

        except Exception as e:
            self.is_depth_retrieving = False
            err = str(e)[:150]
            self.get_logger().error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {err}")
            feedback.feedback_msg = f"å¤„ç†å¼‚å¸¸: {err[:80]}ï¼Œä»»åŠ¡ç»ˆæ­¢"
            feedback.elapsed_time = round(time.time() - self.total_start, 3)
            goal_handle.publish_feedback(feedback)

            result.success = False
            result.intent = ""
            result.message = f"å¤„ç†å¤±è´¥ï¼š{err}"
            goal_handle.abort()

        return result

# ---------------------- ä¸»å‡½æ•°ï¼ˆç²¾ç®€ï¼Œæ— å†—ä½™ï¼‰----------------------
def main(args=None):
    rclpy.init(args=args)
    node = IntentClassifyAnswerServer()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.is_depth_retrieving = False
        node.get_logger().info("\nğŸ“¤ æ”¶åˆ°ç»ˆç«¯ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…åœæ­¢æœåŠ¡ç«¯...")
    finally:
        node._action_server.destroy()
        node.destroy_node()
        rclpy.shutdown()
        print("\nâœ… è§†è§‰é—®ç­”æœåŠ¡ç«¯å·²å®Œå…¨åœæ­¢ï¼Œèµ„æºé‡Šæ”¾å®Œæˆï¼")

if __name__ == '__main__':
    main()